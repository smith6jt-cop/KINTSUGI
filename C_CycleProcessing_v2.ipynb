{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de152bce-3aae-4e74-b337-ff06e0345601",
   "metadata": {},
   "source": [
    "# KINTSUGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9b613-22fc-40c7-a4a3-e5f0b1cb9f73",
   "metadata": {},
   "source": [
    "## In the following notebook you will use the parameters found in A_Evaluation&Testing.ipynb to correct and stitch entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20908051-79d7-4e17-8725-587ca5084c2b",
   "metadata": {},
   "source": [
    "### 1. Import packages. *This must be done every time the notebook is started or restarted.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743639-2916-4aaa-bcd4-e235c0bbc47e",
   "metadata": {},
   "source": [
    "Import these packages. Run cells using Ctrl+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b61c7f-445a-466f-a3d3-dfefa0d45258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import os as os\n",
    "from tqdm import trange\n",
    "import cupy as cp\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import simpledialog\n",
    "import pandas as pd\n",
    "from m2stitch import stitch_images\n",
    "from basicpy import BaSiC, metrics\n",
    "from glob import glob\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "import shutil\n",
    "from hyperactive import Hyperactive\n",
    "import numpy as np\n",
    "from skimage.io import imread \n",
    "from skimage.io import imsave\n",
    "from skimage import io\n",
    "from skimage import util\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import pickle\n",
    "from itertools import chain, repeat\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import imagej, scyjava\n",
    "current_dateTime = datetime.now()\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2ab6-e1f7-45b0-96c2-a2a691807caf",
   "metadata": {},
   "source": [
    "### 2. Define directory paths. *This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879430d-d043-4d6b-9e94-018b36cc7c80",
   "metadata": {},
   "source": [
    "Below are three ways to get the required paths to input, output, and meta folders.  The first is where they can be entered manually.  The second-fourth simply asks for the location of each.  The third reads from the project_data.txt file created in the first notebook and appends the variables to the global variable list.\n",
    "\n",
    "In each of these methods, a text file to store correction parameters is defined.\n",
    "\n",
    "Choose only one method: A, B, or C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d14b24-d405-4382-8199-698348661149",
   "metadata": {},
   "source": [
    "### 2.1 Method A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2736065-d891-45e8-a56e-8190ce6028e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_raw.\n",
      "Stitching folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_BaSiC_Stitched.\n",
      "Meta folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_meta.\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/Users/smith6jt/KINTSUGI\"\n",
    "image_dir =\"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_raw\"\n",
    "stitch_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_BaSiC_Stitched\"\n",
    "meta_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_meta\"\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Image folder is {image_dir}.\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c178c6-981c-47c4-9014-46acb9d170dd",
   "metadata": {},
   "source": [
    "### 2.2 Method B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117013a-6e2e-4107-8b2e-96f2f6a9ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter image input directory.\n",
    "image_dir = filedialog.askdirectory()\n",
    "print(f\"Image folder is {image_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d3259-7c77-48e9-b524-e57a43466c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter stitching output directory.\n",
    "stitch_dir = filedialog.askdirectory()\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a42eae-1858-4baa-842f-9c5bce0de580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the metadata directory.\n",
    "stitch_dir = filedialog.askdirectory()\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bdf412-2342-4d4e-a085-969767c20df2",
   "metadata": {},
   "source": [
    "### 2.3 Method C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484d5ce-c10f-4b76-a803-90de670da538",
   "metadata": {},
   "source": [
    "If folder names were saved previously, import them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a9094-7aea-466b-a689-f5c1ae6e6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the metadata directory.\n",
    "meta_dir = filedialog.askdirectory()\n",
    "project_filename = os.path.join(meta_dir, \"project_data.txt\")\n",
    "with open(project_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                var_name, var_value = line.split('=')\n",
    "                if var_name in globals():\n",
    "                    print(f\"{var_name} is {var_value}\")\n",
    "            except (ValueError):\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986ebe1-7f2e-4591-b8df-a6dbd6a21eeb",
   "metadata": {},
   "source": [
    "### 3. Stitching and Illumination Correction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713805",
   "metadata": {},
   "source": [
    "### 3.1 Stitching Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d7e45",
   "metadata": {},
   "source": [
    "The following cell defines the function that is called from the apply_basic function to stitch the corrected tiles.  It creates the model from the middle z-plane images of the first channel, and then applies the model to the rest of the images for all channels in the cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8598a778-b89c-4872-a1c6-a03819c37d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(images_transformed, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage):\n",
    "    \n",
    "    z = str(zplanes)\n",
    "    ch = str(channels)\n",
    "    pkl_dest = os.path.join(dest, \"result_df.pkl\")\n",
    "    \n",
    "    if zplanes == zplanes_n//2 and channels == 1:\n",
    "        # print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(pkl_dest):\n",
    "            result_df = pd.read_pickle(pkl_dest)\n",
    "        else:\n",
    "            result_df, _ = stitch_images(images_transformed, rows, cols, initial_ncc_threshold=0.0, overlap_percentage=overlap_percentage, pou=pou, max_cores=10)\n",
    "            result_df.to_pickle(pkl_dest)\n",
    "            cp._default_memory_pool.free_all_blocks()\n",
    "        \n",
    "    else:\n",
    "        # print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(os.path.join(dest_1, \"result_df.pkl\")):\n",
    "            result_df = pd.read_pickle(os.path.join(dest_1, \"result_df.pkl\"))\n",
    "\n",
    "        else:\n",
    "            print(\"Run registration channel to produce a stitching model.\")\n",
    "\n",
    "    result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "    result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "    \n",
    "    size_y = images_transformed.shape[1]\n",
    "    size_x = images_transformed.shape[2]\n",
    "    \n",
    "    stitched_image_size = (\n",
    "        result_df[\"y_pos2\"].max() + size_y,\n",
    "        result_df[\"x_pos2\"].max() + size_x,\n",
    "    )\n",
    "    stitched_image = np.zeros_like(images_transformed, shape=stitched_image_size)\n",
    "    \n",
    "    for i, row in result_df.iterrows():\n",
    "        stitched_image[\n",
    "            row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "            row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "        ] = images_transformed[i]\n",
    "\n",
    "    result_image_file_path = os.path.join(dest,f\"{z.zfill(2)}.tif\") \n",
    "    imsave(result_image_file_path, stitched_image, check_contrast=False)\n",
    "    \n",
    "    # print(f\"Saved to {result_image_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ff441",
   "metadata": {},
   "source": [
    "### 3.2 Illumination Correction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4328b6a-0eb6-4499-9e7e-27f040a60a14",
   "metadata": {},
   "source": [
    "The following cell contains the function that will apply the BaSiC correction to your data.  Make sure the number of leading zero digits in your cycle folder names is correct for 'zeros' and the filename pattern is correct for 'im_raw'.  This function runs BaSiC for the middle z-plane images and then reuses the correction model for the rest of the channel's images.  It then calls the stitching function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a6802-1694-4881-85cf-21821ba0439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_basic(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage):\n",
    "    \n",
    "    max_basic_workers = os.cpu_count()\n",
    "    zeros = 3\n",
    "    quant = 0.95\n",
    "    filename_pattern = f'1_000??_Z0{str(zplanes).zfill(2)}_CH{str(channels)}.tif'\n",
    "    \n",
    "    dest = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", f\"CH{str(channels)}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    dest_1 = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", \"CH1\")\n",
    "    \n",
    "    im_raw = sorted(glob(os.path.join(image_dir, f'cyc{str(cycles).zfill(zeros)}', filename_pattern)), key=alphanumeric_key)\n",
    "    im = io.imread_collection(im_raw)\n",
    "    im_array = np.asarray(im)\n",
    "    if np.min(im_array) != 0:\n",
    "        im_array = im_array - np.min(im_array)\n",
    "    # im_i_max, im_i_min = np.max(im_array), np.min(im_array)\n",
    "    # print(f\"Cycle {cycles} channel {channels} z-plane {zplanes} min, max is {im_i_min}, {im_i_max} range is {im_i_max - im_i_min}\") \n",
    "    # im_array = exposure.rescale_intensity(im_array, out_range=(0, 1))\n",
    "    \n",
    "    if zplanes == zplanes_n//2:\n",
    "\n",
    "        # print(f\"Start Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "        basic = BaSiC(max_workers=max_basic_workers, max_reweight_iterations=30, max_reweight_iterations_baseline=40)\n",
    "        basic.autotune(im_array, random_state=0, early_stop=False, histogram_qmin=1-quant, histogram_qmax=quant, search_space={\"smoothness_flatfield\": list(np.logspace(-1, 1, 10))}, init_params={\"smoothness_flatfield\": 0.1})\n",
    "        # basic=BaSiC.load_model(os.path.join(dest, \"basic_first\"))\n",
    "\n",
    "        images_transformed_ff = basic.fit_transform(im_array)\n",
    "        basic.save_model(os.path.join(dest, \"basic_first\"), overwrite=True)\n",
    "        # ratio_1 = 1 / 1\n",
    "        # print(f\"Image quantile: {np.quantile(im_array, quant)} flatfield quantile: {np.quantile(basic.flatfield, quant)}\")\n",
    "        # print(f\"Cycle {cycles} channel {channels} z-plane {zplanes} first ratio: {ratio_1}\")      \n",
    "        # images_transformed_ff = exposure.rescale_intensity(images_transformed_ff, out_range=(0, 1)) \n",
    "              \n",
    "        basic_2 = BaSiC(fitting_mode='approximate', get_darkfield=True, sort_intensity=True, max_workers=max_basic_workers)\n",
    "        basic_2.autotune(images_transformed_ff, random_state=0, n_iter=50, early_stop_n_iter_no_change=8, histogram_bins=100, histogram_qmax=0.6, \n",
    "                        search_space={\"smoothness_flatfield\": [0.1],\n",
    "                                    \"smoothness_darkfield\": list(np.logspace(-5, 1, 10)),\n",
    "                                    \"sparse_cost_darkfield\": list(np.logspace(-5, 1, 10))},\n",
    "                        init_params={\"smoothness_flatfield\": 0.1,\n",
    "                                    \"smoothness_darkfield\": 1e-5,\n",
    "                                    \"sparse_cost_darkfield\": 1e-5})               \n",
    "        # basic_2 = BaSiC.load_model(os.path.join(dest, \"basic_second\"))\n",
    "        images_transformed = basic_2.fit_transform(images_transformed_ff)\n",
    "        basic_2.save_model(os.path.join(dest, \"basic_second\"), overwrite=True)\n",
    "        # print(f\"Done Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        print(f\"Start Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "        basic = BaSiC.load_model(os.path.join(dest, \"basic_first\"))\n",
    "        # ratio_2 = 1 / np.abs(8-zplanes)\n",
    "        # fitting_2 = basic.flatfield * ratio_2 * np.ones_like(im_array)\n",
    "        images_transformed_ff2 = basic.fit_transform(im_array)\n",
    "        \n",
    "        # print(f\"Image quantile: {np.quantile(im_array, quant)} flatfield quantile: {np.quantile(basic.flatfield, quant)}\")\n",
    "        # print(f\"Cycle {cycles} channel {channels} z-plane {zplanes} first ratio: {ratio_1}\")\n",
    "        # if 0 > ratio_1:\n",
    "        #     print(\"Negative ratio. Multiplying by -1.\")\n",
    "        #     ratio_1 = ratio_1 * -1\n",
    "        #     fitting_1 = basic.flatfield * ratio_1 * np.ones_like(im_array)\n",
    "        #     images_transformed_ff2 = basic.fit_transform(im_array, fitting_1)\n",
    "        # if np.isinf(ratio_1):\n",
    "        #     print(\"Infinite ratio. Using no first fitting weight.\")\n",
    "        #     # fitting_1 = basic.flatfield / ratio_1 * np.ones_like(im_array)\n",
    "        #     images_transformed_ff2 = basic.fit_transform(im_array)\n",
    "        # else:\n",
    "        #     print(\"Using first multiplier fitting weight.\")\n",
    "        #     fitting_1 = basic.flatfield * ratio_1 * np.ones_like(im_array)\n",
    "        #     images_transformed_ff2 = basic.fit_transform(im_array, fitting_1)\n",
    "        \n",
    "        basic_3 = BaSiC.load_model(os.path.join(dest, \"basic_second\"))\n",
    "        # basic_3.autotune(im_array, random_state=0, histogram_bins=50, histogram_qmin=1-quant, histogram_qmax=quant, \n",
    "        #                 early_stop_n_iter_no_change=5, early_stop_tolerance=0.001,\n",
    "        #                 search_space={\"smoothness_flatfield\": list(np.logspace(-1, 1, 10)),\n",
    "        #                             \"smoothness_darkfield\": list(np.logspace(-5, 1, 10)),\n",
    "        #                             \"sparse_cost_darkfield\": list(np.logspace(-5, 1, 10))},\n",
    "        #                 init_params={\"smoothness_flatfield\": basic_3.settings.get(\"smoothness_flatfield\"),\n",
    "        #                             \"smoothness_darkfield\": basic_3.settings.get(\"smoothness_darkfield\"),\n",
    "        #                             \"sparse_cost_darkfield\": basic_3.settings.get(\"sparse_cost_darkfield\")})\n",
    "        # ratio_3 = 1 / np.abs(8-zplanes)\n",
    "        # fitting_3 = basic.darkfield * ratio_3 * np.ones_like(images_transformed_ff2)\n",
    "        images_transformed = basic_3.fit_transform(images_transformed_ff2)\n",
    "        # # print(f\"Image quantile: {np.quantile(images_transformed_ff2, 1-quant)} darkfield quantile: {np.quantile(basic_2.darkfield, 1-quant)}\")\n",
    "        # print(f\"Cycle {cycles} channel {channels} z-plane {zplanes} second ratio: {ratio_2}\")\n",
    "        # if 0 > ratio_2:\n",
    "        #     print(\"Negative ratio. Multiplying by -1.\")\n",
    "        #     ratio_2 = ratio_2 * -1\n",
    "        #     fitting_2 = basic_2.darkfield * ratio_2 * np.ones_like(images_transformed_ff2)\n",
    "        #     images_transformed = basic_2.fit_transform(images_transformed_ff2, fitting_2)\n",
    "        # if np.isinf(ratio_2):\n",
    "        #     print(\"Infinite ratio. Using no second fitting weight.\")\n",
    "        #     images_transformed = basic_2.fit_transform(images_transformed_ff2)\n",
    "        # else:\n",
    "        #     print(\"Using second multiplier fitting weight.\")\n",
    "        #     fitting_2 = basic_2.darkfield * ratio_2 * np.ones_like(images_transformed_ff2)\n",
    "        #     images_transformed = basic_2.fit_transform(images_transformed_ff2, fitting_2)\n",
    "       \n",
    "        print(f\"Done Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "\n",
    "    im_t_max, im_t_min = np.max(images_transformed), np.min(images_transformed)\n",
    "    print(f\"Cycle {cycles} channel {channels} z-plane {zplanes} min, max is {im_t_min}, {im_t_max} range is {im_t_max - im_t_min}\")\n",
    "    if np.min(images_transformed) != 0:\n",
    "        images_transformed = images_transformed - np.min(images_transformed)   \n",
    "    images_transformed = exposure.match_histograms(images_transformed, im_array).astype(np.uint16) \n",
    "    # images_transformed = exposure.rescale_intensity(images_transformed, out_range=(0, 65535)).astype(np.uint16)\n",
    "    # images_transformed = exposure.equalize_adapthist(images_transformed, kernel_size=500, clip_limit=0.0, nbins=100).astype(np.uint16)\n",
    "                                              \n",
    "    stitch(images_transformed, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627091e-c1aa-4a7e-b6ef-a570bf28932d",
   "metadata": {},
   "source": [
    "### 3.3 Running multiple cycle/channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18604-75ad-4533-a9f9-b5dbe9785475",
   "metadata": {},
   "source": [
    "This cell runs the above two functions for all the images you define with start_cycle, end_cycle, start_channel, and end_channel.  You must enter these values as well as n, m, pou (determined from the first notebook), zplanes_n (number of zplanes), and overlap_percentage.  You must also enter the number of workers for the multithreading (usually determined by dataset size, available memory, and number of cores).  See https://docs.python.org/3/library/concurrent.futures.html\n",
    "\n",
    "To run just one cycle or channel, simply enter the same number for both start and end.\n",
    "\n",
    "If problems with the jupyter kernel restarting becomes an issue, decrease the number of workers, or close other programs to conserve resources.  You can also try reducing the histogram bins, number of iterations, and/or early_stop_n_iter_no_change values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b424938e-9262-4232-807c-eee1bb6ead4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin_init: 1735.0 vmax_init: 31877.0 val_range_init: 46254.0\n",
      "vmin: 1749.19580078125 vmax: 31933.834082031215 val_range: 46326.4749023437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   0%|\u001b[33m          \u001b[0m| 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin_new: 1049.51748046875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   2%|\u001b[33m          \u001b[0m| 2/100 [00:06<10:48,  6.62s/it, best_iter=0, best_pos=[0], best_score=-127.99927837293735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.64912489850509, Fourier L0 norm: 118.35015347443226\n",
      "vmin_new: 1057.731884765625 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   8%|\u001b[33m          \u001b[0m| 8/100 [00:14<06:50,  4.46s/it, best_iter=0, best_pos=[1], best_score=-83.04059896228148] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.639478070203193, Fourier L0 norm: 73.40112089207828\n",
      "vmin_new: 1063.0373291015624 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   9%|\u001b[33m          \u001b[0m| 9/100 [00:20<02:47,  1.84s/it, best_iter=0, best_pos=[2], best_score=-9.631741219032284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.631741219032284, Fourier L0 norm: 0\n",
      "vmin_new: 1061.986376953125 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  11%|\u001b[33m─         \u001b[0m| 11/100 [00:23<03:08,  2.12s/it, best_iter=0, best_pos=[2], best_score=-9.631741219032284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.631280751565638, Fourier L0 norm: 0\n",
      "vmin_new: 1063.0494140624999 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  14%|\u001b[33m─         \u001b[0m| 14/100 [00:27<02:59,  2.09s/it, best_iter=0, best_pos=[4], best_score=-9.631280751565638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.632027790522562, Fourier L0 norm: 0\n",
      "vmin_new: 1056.226611328125 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  18%|\u001b[33m─         \u001b[0m| 18/100 [00:31<02:24,  1.77s/it, best_iter=0, best_pos=[4], best_score=-9.631280751565638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.631548085373108, Fourier L0 norm: 0\n",
      "vmin_new: 1059.7975341796875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  21%|\u001b[33m──        \u001b[0m| 21/100 [00:35<01:53,  1.44s/it, best_iter=0, best_pos=[5], best_score=-9.631247259241302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.631247259241302, Fourier L0 norm: 0\n",
      "vmin_new: 1040.3156982421874 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  28%|\u001b[33m──        \u001b[0m| 28/100 [00:40<01:45,  1.46s/it, best_iter=0, best_pos=[5], best_score=-9.631247259241302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.635427253036614, Fourier L0 norm: 0\n",
      "vmin_new: 1050.3111328124999 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  45%|\u001b[33m────      \u001b[0m| 45/100 [00:44<00:56,  1.02s/it, best_iter=0, best_pos=[5], best_score=-9.631247259241302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 9.631819883624747, Fourier L0 norm: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  78%|\u001b[33m───────   \u001b[0m| 78/100 [00:47<00:05,  4.16it/s, best_iter=0, best_pos=[9], best_score=-1e-15]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin_new: 1040.9998535156249 \n",
      "Flatfield is all ones, returning -1e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing): 100%|\u001b[32m──────────\u001b[0m| 100/100 [00:47<00:00,  2.10it/s, best_iter=0, best_pos=[9], best_score=-1e-15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results: 'fit_and_calc_entropy'  \n",
      "   Best score: -1e-15  \n",
      "   Best parameter set:\n",
      "      'smoothness_flatfield' : 10.0  \n",
      "   Best iteration: 0  \n",
      " \n",
      "   Random seed: 0  \n",
      " \n",
      "   Evaluation time   : 47.23056674003601 sec    [99.99 %]\n",
      "   Optimization time : 0.004199028015136719 sec    [0.01 %]\n",
      "   Iteration time    : 47.23476576805115 sec    [2.12 iter/sec]\n",
      " \n",
      "vmin_init: 1059.9998779296875 vmax_init: 4834.99951171875 val_range_init: 6298.499377441407\n",
      "vmin: 498.05233673095705 vmax: 4384.427734375 val_range: 6128.394498504638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   0%|\u001b[33m          \u001b[0m| 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin_new: 298.8314020385742 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   2%|\u001b[33m          \u001b[0m| 1/50 [00:03<03:07,  3.82s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.495387058377709, Fourier L0 norm: 54.16901453335515\n",
      "vmin_new: 298.83629150390624 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):   6%|\u001b[33m          \u001b[0m| 3/50 [00:08<03:29,  4.46s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.49538245512433, Fourier L0 norm: 54.16973881099685\n",
      "vmin_new: 298.8361074829101 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  10%|\u001b[33m─         \u001b[0m| 5/50 [00:13<02:17,  3.06s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.495382548012055, Fourier L0 norm: 54.176257309772105\n",
      "vmin_new: 317.57134936523437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  12%|\u001b[33m─         \u001b[0m| 6/50 [00:17<01:56,  2.65s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.492118546899698, Fourier L0 norm: 52.97250786927657\n",
      "vmin_new: 369.3507194824219 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  14%|\u001b[33m─         \u001b[0m| 7/50 [00:22<02:14,  3.12s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.482542095766734, Fourier L0 norm: 44.175069494439725\n",
      "vmin_new: 298.8364740600586 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  16%|\u001b[33m─         \u001b[0m| 8/50 [00:26<02:26,  3.50s/it, best_iter=0, best_pos=[0 0 0], best_score=-62.66440159173286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.495382482079117, Fourier L0 norm: 54.17589517095126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  22%|\u001b[33m──        \u001b[0m| 11/50 [00:27<01:49,  2.81s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: INVALID_ARGUMENT: Unbound parameter: %param_0.35 = s32[2]{0} parameter(0), returning -1e-15\n",
      "vmin_new: 298.83603405761716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  24%|\u001b[33m──        \u001b[0m| 12/50 [00:32<01:19,  2.10s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.495382552316778, Fourier L0 norm: 54.16829025571346\n",
      "vmin_new: 299.3004765014648 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  26%|\u001b[33m──        \u001b[0m| 13/50 [00:36<01:35,  2.59s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.49532069146087, Fourier L0 norm: 54.11469371022809\n",
      "vmin_new: 298.83121710205074 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  30%|\u001b[33m───       \u001b[0m| 15/50 [00:41<01:49,  3.14s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.495387093450237, Fourier L0 norm: 54.1624960345799\n",
      "vmin_new: 368.97634204101564 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  32%|\u001b[33m───       \u001b[0m| 16/50 [00:46<01:36,  2.85s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.482837276526698, Fourier L0 norm: 44.39017995402286\n",
      "vmin_new: 375.1192745361328 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] fit_and_calc_entropy (Hill Climbing):  32%|\u001b[32m───       \u001b[0m| 16/50 [00:51<01:48,  3.20s/it, best_iter=0, best_pos=[0 0 1], best_score=-1e-15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 8.47587861069215, Fourier L0 norm: 43.24437272486284\n",
      "\n",
      "\n",
      "Results: 'fit_and_calc_entropy'  \n",
      "   Best score: -1e-15  \n",
      "   Best parameter set:\n",
      "      'smoothness_flatfield'  : 0.1  \n",
      "      'smoothness_darkfield'  : 1e-05  \n",
      "      'sparse_cost_darkfield' : 4.641588833612782e-05  \n",
      "   Best iteration: 0  \n",
      " \n",
      "   Random seed: 0  \n",
      " \n",
      "   Evaluation time   : 51.05472135543823 sec    [100.0 %]\n",
      "   Optimization time : 0.0012307167053222656 sec    [0.0 %]\n",
      "   Iteration time    : 51.055952072143555 sec    [1.02 sec/iter]\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 1 channel 4 z-plane 8 min, max is -2615.69677734375, 98045.171875 range is 100660.8671875\n",
      "Start Illumination Correction cyc01 Z001_CH4\n",
      "Start Illumination Correction cyc01 Z002_CH4\n",
      "Start Illumination Correction cyc01 Z006_CH4\n",
      "Start Illumination Correction cyc01 Z003_CH4\n",
      "Start Illumination Correction cyc01 Z004_CH4\n",
      "Start Illumination Correction cyc01 Z005_CH4\n",
      "Start Illumination Correction cyc01 Z007_CH4\n",
      "Start Illumination Correction cyc01 Z009_CH4\n",
      "Done Illumination Correction cyc01 Z001_CH4\n",
      "Cycle 1 channel 4 z-plane 1 min, max is -3026.767822265625, 59173.0546875 range is 62199.82421875\n",
      "Done Illumination Correction cyc01 Z002_CH4\n",
      "Cycle 1 channel 4 z-plane 2 min, max is -3259.625732421875, 63637.62109375 range is 66897.25\n",
      "Done Illumination Correction cyc01 Z003_CH4Done Illumination Correction cyc01 Z007_CH4\n",
      "\n",
      "Cycle 1 channel 4 z-plane 7 min, max is -2342.645751953125, 100532.0703125 range is 102874.71875\n",
      "Cycle 1 channel 4 z-plane 3 min, max is -3405.1865234375, 72059.4140625 range is 75464.6015625\n",
      "Done Illumination Correction cyc01 Z009_CH4\n",
      "Cycle 1 channel 4 z-plane 9 min, max is -2780.21826171875, 94874.109375 range is 97654.328125\n",
      "Done Illumination Correction cyc01 Z006_CH4Done Illumination Correction cyc01 Z005_CH4\n",
      "\n",
      "Done Illumination Correction cyc01 Z004_CH4\n",
      "Cycle 1 channel 4 z-plane 5 min, max is -2537.324462890625, 90349.8359375 range is 92887.1640625\n",
      "Cycle 1 channel 4 z-plane 6 min, max is -2345.61474609375, 95184.8203125 range is 97530.4375\n",
      "Cycle 1 channel 4 z-plane 4 min, max is -3518.242919921875, 77643.703125 range is 81161.9453125\n",
      "Start Illumination Correction cyc01 Z010_CH4\n",
      "Start Illumination Correction cyc01 Z011_CH4\n",
      "Start Illumination Correction cyc01 Z012_CH4\n",
      "Done Illumination Correction cyc01 Z010_CH4\n",
      "Cycle 1 channel 4 z-plane 10 min, max is -2647.7587890625, 95276.671875 range is 97924.4296875\n",
      "Start Illumination Correction cyc01 Z013_CH4\n",
      "Start Illumination Correction cyc01 Z014_CH4\n",
      "Start Illumination Correction cyc01 Z015_CH4\n",
      "Start Illumination Correction cyc01 Z017_CH4\n",
      "Start Illumination Correction cyc01 Z016_CH4\n",
      "Done Illumination Correction cyc01 Z011_CH4\n",
      "Cycle 1 channel 4 z-plane 11 min, max is -2616.62841796875, 86237.171875 range is 88853.796875\n",
      "Done Illumination Correction cyc01 Z012_CH4\n",
      "Cycle 1 channel 4 z-plane 12 min, max is -2781.9052734375, 75660.25 range is 78442.15625\n",
      "Done Illumination Correction cyc01 Z015_CH4\n",
      "Cycle 1 channel 4 z-plane 15 min, max is -2877.1728515625, 49728.82421875 range is 52605.99609375\n",
      "Done Illumination Correction cyc01 Z017_CH4\n",
      "Cycle 1 channel 4 z-plane 17 min, max is -3208.554443359375, 41114.26953125 range is 44322.82421875\n",
      "Done Illumination Correction cyc01 Z016_CH4\n",
      "Done Illumination Correction cyc01 Z014_CH4\n",
      "Cycle 1 channel 4 z-plane 16 min, max is -2861.91455078125, 45286.0859375 range is 48148.0\n",
      "Cycle 1 channel 4 z-plane 14 min, max is -3024.641845703125, 56037.984375 range is 59062.625Done Illumination Correction cyc01 Z013_CH4\n",
      "\n",
      "Cycle 1 channel 4 z-plane 13 min, max is -2787.17236328125, 63752.57421875 range is 66539.75\n"
     ]
    }
   ],
   "source": [
    "n = 9  # Number of rows (height)\n",
    "m = 7  # Number of columns (width)\n",
    "\n",
    "# Row coordinates: each row index is repeated m times\n",
    "rows = list(chain.from_iterable(repeat(row, m) for row in range(n)))\n",
    "# Column coordinates: snake pattern for each row, going back and forth from top left going right\n",
    "cols = list(chain.from_iterable(range(m) if row % 2 == 0 else range(m - 1, -1, -1) for row in range(n)))\n",
    "\n",
    "start_cycle = 1\n",
    "end_cycle = 1\n",
    "start_channel = 4\n",
    "end_channel = 4\n",
    "pou = 13\n",
    "zplanes_n = 17\n",
    "overlap_percentage = 0.30\n",
    "workers = (zplanes_n-1)//2\n",
    "\n",
    "image_dir_list = [image_dir] * (zplanes_n-1)\n",
    "stitch_dir_list = [stitch_dir] * (zplanes_n-1)\n",
    "zplanes_list =[zplanes_n] * (zplanes_n-1)\n",
    "pou_list = [pou] * (zplanes_n-1)\n",
    "rows_list = [rows] * (zplanes_n-1)\n",
    "cols_list = [cols] * (zplanes_n-1)\n",
    "overlap_percentage_list = [overlap_percentage] * (zplanes_n-1)\n",
    "\n",
    "\n",
    "for j in range(start_cycle, end_cycle+1):\n",
    "    for i in range(start_channel, end_channel+1):\n",
    "\n",
    "        cycles = j\n",
    "        zplanes = zplanes_n//2 \n",
    "        channels = i\n",
    "        apply_basic(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage)\n",
    "        \n",
    "        if __name__ ==  '__main__':\n",
    "            with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "                cycles = [j] * (zplanes_n-1) \n",
    "                zplanes =  list(range(1, zplanes_n//2))+list(range((zplanes_n//2)+1, zplanes_n+1)) \n",
    "                channels = [i] * (zplanes_n-1)\n",
    "                executor.map(apply_basic, image_dir_list, stitch_dir_list, zplanes, cycles, channels, zplanes_list, pou_list, rows_list, cols_list, overlap_percentage_list) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3723d-e254-4bd1-bb5b-639f35e66dcc",
   "metadata": {},
   "source": [
    "### 4. Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fefaab-7c4a-4624-b85f-f26644b967f6",
   "metadata": {},
   "source": [
    "Before moving on to the deconvolution step, it is a good idea to review the results thus far.  If they are satisfactory, the parameters for deconvolution discovered in the first notebook can be entered below to define the decon function. Also, if more or all of the cycles have now been stitched, more deconvolution testing can be done on these stacks in the previous notebook before proceeding to a larger run. \n",
    "\n",
    "Be sure the MATLAB Runtime v9.5 (R2018, 64-bit) is installed.  Download for free here: http://www.mathworks.com/products/compiler/mcr/index.html. Reboot your computer after install.  \n",
    "\n",
    "There is no need to supply a point-spread function.\n",
    "\n",
    "The base_dir and stitch_dir definitions used previously will be again used here, and a new folder will be created to save the deconvolved images.  \n",
    "\n",
    "The original deconvolution program was written specifically for lightsheet images. Here the estimation of the point-spread function was modified for use with widefield fluorescence images.  See https://www.nature.com/articles/s41598-019-53875-y for the original publication which includes links to the original code.\n",
    "\n",
    "Output will be written to the terminal.  Check that the first image stack is processed without error.  If there is an \"Maximum variable size allowed on the device is exceeded.\" error, then restart the kernel, decrease the max_GPU or max_CPU parameter, rerun the decon function cell, and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00378f08",
   "metadata": {},
   "source": [
    "### 4.1 Deconvolution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9e249-9b51-4bde-b711-0a40ddcd8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decon(cycles, channels):\n",
    "    \n",
    "    c = str(cycles)\n",
    "    ch = str(channels)\n",
    "\n",
    "    # pixel size in xy dimension (nanometers)\n",
    "    xy_vox = 377\n",
    "    # pixel size in z dimension (nanometers)\n",
    "    z_vox = 1500\n",
    "    # Number of iterations of Lucy-Richardson algo before stopping unless stop_crit is met first\n",
    "    iterations = 100\n",
    "    # Microscope objective numerical aperture\n",
    "    mic_NA = 0.75\n",
    "    # Refractive index of tissue being imaged\n",
    "    tissue_RI = 1.3\n",
    "    # Opening size in millimeters of objective aperture\n",
    "    slit_aper = 6.5\n",
    "    # Focal length in millimeters of objective\n",
    "    f_cyl = 1\n",
    "    # Used to reduce noise.  Increase value for noisy images. (0-10)\n",
    "    damping = 0\n",
    "    # If set, the deconvolved images will be clipped by this percent for max and min values, and then scaled to full range of bit depth. (0-5)\n",
    "    hist_clip = 0.000\n",
    "    # Percent change between iterations to use as criteria to stop deconvolution.\n",
    "    stop_crit = 5.00\n",
    "    # Enter 1 to perform on GPU, 0 to use CPU\n",
    "    GPU = 1\n",
    "    # Percent maximum GPU memory to use if GPU = 1\n",
    "    max_GPU = 25\n",
    "    # Percent maximum RAM to use if GPU = 0\n",
    "    max_CPU = 40\n",
    "    if GPU == 1:\n",
    "        max_block=max_GPU\n",
    "    elif GPU == 0:\n",
    "        max_block=max_CPU\n",
    "\n",
    "    # The respective excitation and emission wavelength in nanometers for each channel\n",
    "    C1ex = 358\n",
    "    C1em = 461\n",
    "    C2ex = 753\n",
    "    C2em = 775\n",
    "    C3ex = 560\n",
    "    C3em = 575\n",
    "    C4ex = 648\n",
    "    C4em = 668\n",
    "    \n",
    "    # The path to the deconvolution executable file.\n",
    "    decon_exe = \"C:/Users/smith6jt/KINTSUGI/LsDeconv.exe\"\n",
    "    stitch_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_BaSiC_Stitched\"\n",
    "    decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "    source = os.path.join(stitch_dir, f\"cyc{c.zfill(2)}\", f\"CH{ch}\")\n",
    "    dest = os.path.join(decon_dir, f\"cyc{c.zfill(2)}\", f\"CH{ch}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting Deconvolution of cyc{c.zfill(2)} CH{ch}\")\n",
    "   \n",
    "    if channels==1:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C1ex), str(C1em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "        # print(result_1.stdout)\n",
    "    if channels==2:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C2ex), str(C2em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    if channels==3:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C3ex), str(C3em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    if channels==4:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C4ex), str(C4em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    # gc.collect()\n",
    "    \n",
    "    try:\n",
    "        os.rename(os.path.join(source, 'deconvolved'), os.path.join(dest, 'deconvolved'))\n",
    "    except (FileNotFoundError):\n",
    "        print(\"Reduce max memory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6e5d-b464-4f7d-bf8f-d3c542249366",
   "metadata": {},
   "source": [
    "To apply the above decon function to multiple cycles/channels, enter the start and end numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd44c0-b01d-473e-ade7-da609559d9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decon_start_cycle = 2\n",
    "decon_end_cycle = 13\n",
    "decon_start_channel = 1\n",
    "decon_end_channel = 4\n",
    "\n",
    "\n",
    "for j in range(decon_start_cycle, decon_end_cycle+1):\n",
    "    \n",
    "    for i in range(decon_start_channel, decon_end_channel+1):\n",
    "        \n",
    "        \n",
    "        decon( j, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948e5f2",
   "metadata": {},
   "source": [
    "### 5. Extended Depth of Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceac06-e6aa-41d0-bbbf-263d7e6d0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej, scyjava\n",
    "ij = imagej.init('C:/Users/smith6jt/Fiji.app', add_legacy=True); print(ij.getVersion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej, scyjava\n",
    "ij_mem = 40\n",
    "GPU_name = \"NVIDIA RTX A4500\"\n",
    "radius_x = 5.0\n",
    "radius_y = 5.0\n",
    "sigma = 20.0\n",
    "edf_start_cycle = 1\n",
    "edf_end_cycle = 13\n",
    "edf_start_channel = 1\n",
    "edf_end_channel = 4\n",
    "scyjava.config.add_option(f'-Xmx{str(ij_mem)}g')\n",
    "ij = imagej.init('C:/Users/smith6jt/Fiji.app', add_legacy=True)\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "edf_dir = decon_dir.replace('_Decon', '_EDF')\n",
    "\n",
    "macro = \"\"\"\n",
    "#@ File in_folder\n",
    "#@ String device\n",
    "#@ File out_folder\n",
    "#@ String file_name\n",
    "#@ Integer radius_x\n",
    "#@ Integer radius_y\n",
    "#@ Integer sigma\n",
    "\n",
    "File.openSequence(in_folder);\n",
    "run(\"CLIJ2 Macro Extensions\", \"cl_device=[\" + device + \"]\");\n",
    "Ext.CLIJ_clear();\n",
    "image1 = \"deconvolved\";\n",
    "Ext.CLIJ2_push(image1);\n",
    "image2 = \"extended_depth_of_focus_variance_projection\";\n",
    "radius_x = 5.0;\n",
    "radius_y = 5.0;\n",
    "sigma = 20.0;\n",
    "Ext.CLIJ2_extendedDepthOfFocusVarianceProjection(image1, image2, radius_x, radius_y, sigma);\n",
    "Ext.CLIJ2_pull(image2);\n",
    "selectImage(image1);\n",
    "close();\n",
    "selectImage(image2);\n",
    "saveAs(\"Tiff\", out_folder + File.separator + file_name);\n",
    "\"\"\"\n",
    "\n",
    "for j in range(edf_start_cycle, edf_end_cycle+1):\n",
    "    \n",
    "    for i in range(edf_start_channel, edf_end_channel+1):\n",
    "\n",
    "        edf_source = os.path.join(decon_dir, f\"cyc{str(j).zfill(2)}\", f\"CH{str(i)}\", \"deconvolved\")\n",
    "        edf_dest = os.path.join(edf_dir, f\"cyc{str(j).zfill(2)}\")\n",
    "        file_name = channel_name_dict.get(f\"cyc{str(j).zfill(2)}.tif\")[i-1]\n",
    "        os.makedirs(edf_dest, exist_ok=True)\n",
    "\n",
    "        args ={'in_folder': edf_source, \"cl_device\" : GPU_name, \"out_folder\" : edf_dest, \"file_name\" : file_name, \"radius_x\" : 5.0, \"radius_y\" : 5.0, \"sigma\" : 20.0}\n",
    "        ij.py.run_macro(macro, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN) #change to INFO for more details\n",
    "# Add vips binaries to path\n",
    "vipshome = 'C:/Users/smith6jt/KINTSUGI/vips-dev-8.16/bin'\n",
    "os.environ['PATH'] = vipshome + ';' + os.environ['PATH']\n",
    "import pyvips \n",
    "# logging.info(\"vips version: \" + str(pyvips.version(0))+\".\"+str(pyvips.version(1))+\".\"+str(pyvips.version(2)))\n",
    "\n",
    "\n",
    "idx = list(range(1, 14))\n",
    "imagedir = 'C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_EDF'\n",
    "outputdir = imagedir #change this to save to a different folder\n",
    "\n",
    "dataSets = glob.glob1(imagedir, f'/cyc{str(idx).zfill(2)}/*.tif')\n",
    "\n",
    "def eval_cb(image, progress):\n",
    "        pbar_filesave.update(progress.percent - pbar_filesave.n)\n",
    "\n",
    "\n",
    "for idx, dataset in enumerate(dataSets):\n",
    "    str1 = dataset.split(\".tif\", 2)\n",
    "    #print(\"Processing: \"+ str1[0] + \" \" + str(idx) + \" out of \" + str(len(dataSets)))\n",
    "    imagePrefix = str1[0]\n",
    "    imageFiles = glob.glob(os.path.join(imagedir, imagePrefix+'.tif'))\n",
    "\n",
    "    outfilename = imagePrefix + '.ome.tif'\n",
    "    outfile = os.path.join(outputdir, outfilename)\n",
    "    pbar_filesave = tqdm(total=100, unit=\"Percent\", desc=outfilename, position=0, leave=True)\n",
    "\n",
    "    images = [pyvips.Image.new_from_file(os.path.join(imagedir, filename), access=\"sequential\") for filename in imageFiles]\n",
    "\n",
    "    out = pyvips.Image.arrayjoin(images, across=1)\n",
    "    out = out.copy()\n",
    "    out.set_type(pyvips.GValue.gint_type, \"page-height\", images[0].height)\n",
    "\n",
    "    # Parameters for OME metadata\n",
    "    width = images[0].width\n",
    "    height = images[0].height\n",
    "\n",
    "    # Need to handle more data types\n",
    "    data_type = \"uint16\"\n",
    "    if (images[0].interpretation==\"grey16\"):\n",
    "        data_type = \"uint16\"\n",
    "        \n",
    "    bands = int(out.height/images[0].height)\n",
    "    CalibrationX = 1000/float(out.xres) #Or out.xres\n",
    "    CalibrationY = 1000/float(out.yres) #Or out.yres\n",
    "    CalibrationUnits = \"µm\" #Or out.get(\"resolution-unit\")\n",
    "    channel_names = channel_name_dict.get(f\"cyc{str(idx).zfill(2)}.tif\")\n",
    "    \n",
    "    # build minimal OME metadata\n",
    "    metadata = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    <OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "        xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\">\n",
    "        <Image ID=\"Image:0\">\n",
    "            <!-- Minimum required fields about image dimensions -->\n",
    "            <Pixels DimensionOrder=\"XYCZT\"\n",
    "                    ID=\"Pixels:0\"\n",
    "                    SizeC=\"{bands}\"\n",
    "                    SizeT=\"1\"\n",
    "                    SizeX=\"{width}\"\n",
    "                    SizeY=\"{height}\"\n",
    "                    SizeZ=\"1\"\n",
    "                    Type=\"{data_type}\"\n",
    "                    PhysicalSizeX=\"{CalibrationX}\"\n",
    "                    PhysicalSizeXUnit=\"{CalibrationUnits}\"\n",
    "                    PhysicalSizeY=\"{CalibrationY}\"\n",
    "                    PhysicalSizeYUnit=\"{CalibrationUnits}\">\n",
    "                <Channel ID=\"Channel:0\" Color=\"16711935\" Name={channel_names[0]} SamplesPerPixel=\"1\" />\n",
    "                <Channel ID=\"Channel:1\" Color=\"-1208024833\" Name={channel_names[1]} SamplesPerPixel=\"1\" />\n",
    "                <Channel ID=\"Channel:2\" Color=\"1828651263\" Name={channel_names[2]} SamplesPerPixel=\"1\" />\n",
    "                <Channel ID=\"Channel:3\" Color=\"11206655\" Name={channel_names[3]} SamplesPerPixel=\"1\" />\n",
    "            </Pixels>\n",
    "        </Image>\n",
    "    </OME>\"\"\"\n",
    "\n",
    "    out.set_type(pyvips.GValue.gstr_type, \"image-description\", metadata)\n",
    "    out.set_progress(True)\n",
    "    out.signal_connect('eval', eval_cb)\n",
    "    \n",
    "    out.write_to_file(outfile, compression='lzw', subifd=True, bigtiff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae4cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KINTSUGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
