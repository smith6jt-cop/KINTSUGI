{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70757bf8-43c1-44be-bcac-c043f60a5ab3",
   "metadata": {},
   "source": [
    "# KINTSUGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075ff64-ea13-4c1b-8f69-47c979a96bc7",
   "metadata": {},
   "source": [
    "## In the following notebook you will prepare for processing your images; test illumination correction parameters, stitching accuracy, and deconvolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f7e67-4eef-47be-a0b8-e58b1a1a226c",
   "metadata": {},
   "source": [
    "## 1. Import packages. This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114cc16-3223-4f54-9df4-23edac70baab",
   "metadata": {},
   "source": [
    "Import these packages.  Run cells using Ctrl+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ee6268-6f89-4723-8131-903faf651249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import gc\n",
    "import os\n",
    "import tkinter as tk\n",
    "import errno\n",
    "from tkinter import filedialog\n",
    "from tkinter import simpledialog\n",
    "import pandas as pd\n",
    "from m2stitch import stitch_images\n",
    "from basicpy import BaSiC, metrics\n",
    "from glob import glob\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "import shutil\n",
    "from hyperactive import Hyperactive\n",
    "import numpy as np\n",
    "from skimage.io import imread \n",
    "from skimage.io import imsave\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import pickle\n",
    "from itertools import chain, repeat\n",
    "import subprocess\n",
    "import imagej, scyjava\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7cc0c-8265-47f4-9c1e-fd31f91e6e19",
   "metadata": {},
   "source": [
    "## 2. Define directory paths.  *This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01d8b3-2631-4e18-b16b-ffdbb41e1d7d",
   "metadata": {},
   "source": [
    "If you are familiar with defining directories, enter them below.  If not the other cells will assist with the necessary definitions.\n",
    "\n",
    "Below are two ways to get the required paths to input, output, and meta folders.  The first is where they can be entered manually.  The second assists with the process.  \n",
    "\n",
    "Choose only one method: A or B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dce6bf-fa12-4587-80f1-b84e0aef58d1",
   "metadata": {},
   "source": [
    "### 2.1 Method A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be45f614-5f53-4099-81d0-be16ece5577c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder is C:/Users/smith6jt/1904_CC2B28_raw.\n",
      "Stitching folder is C:/Users/smith6jt/1904_CC2B28_BaSiC_Stitched.\n",
      "Meta folder is C:/Users/smith6jt/1904_CC2B28_meta.\n"
     ]
    }
   ],
   "source": [
    "image_dir =\"C:/Users/smith6jt/1904_CC2B28_raw\"\n",
    "stitch_dir = \"C:/Users/smith6jt/1904_CC2B28_BaSiC_Stitched\"\n",
    "meta_dir = \"C:/Users/smith6jt/1904_CC2B28_meta\"\n",
    "print(f\"Image folder is {image_dir}.\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8164e3d-7a37-4617-9c04-30dbad6854c6",
   "metadata": {},
   "source": [
    "### 2.1 Method B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37747e8c-864c-455a-8b3a-0c59f8937fd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "First, assess the folder and file names.  For example, in CODEX output, the original folder name is something like CX_20-008_SP_CC2-B. We can shorten that now to make life easier down the road.  Shorten the folder name to remove redundant information.  In this example we choose \"2008_CC2B_raw\" making sure the '_raw' is the last part.\n",
    "\n",
    "Running the following cell will bring up a dialog window where you will enter the new folder name and select the folder containing your images.  This folder will be renamed designated as the image_dir for the project.  An stitching output folder and a folder for metadata files will also be created.  Make sure there are only a series of folders each containing the images for each cycle in the folder you select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73dd7f8-19ed-4cd3-9471-a4c6e6f58ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "user_choice = simpledialog.askstring(\"Shortened name\", \"Enter shortened file name with _raw at end\")\n",
    "image_dir_long = filedialog.askdirectory()\n",
    "head_dir, tail_dir = os.path.split(image_dir_long)\n",
    "\n",
    "try:  \n",
    "    os.rename(image_dir_long, os.path.join(head_dir, user_choice))\n",
    "except FileNotFoundError:\n",
    "    print(\"The file or directory does not exist.\")\n",
    "except PermissionError:\n",
    "    print(\"you don't have permissions to rename the file\")\n",
    "except OSError as error:\n",
    "    print(f\"Error: {error}\")\n",
    "\n",
    "if os.path.isdir(os.path.join(head_dir, user_choice)) == True:\n",
    "    image_dir = os.path.join(head_dir, user_choice)\n",
    "    print(f\"{image_dir_long} renamed to {image_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"Error in renaming.\")\n",
    "    \n",
    "stitch_dir = image_dir.replace('_raw', '_BaSiC_Stitched')\n",
    "meta_dir = image_dir.replace('_raw', '_meta')\n",
    "os.makedirs(stitch_dir, exist_ok=True)\n",
    "os.makedirs(meta_dir, exist_ok=True)\n",
    "\n",
    "if os.path.isdir(stitch_dir) == True:\n",
    "    print(f\"Stitching output folder: {stitch_dir} created successfully.\")\n",
    "\n",
    "else:\n",
    "    print(\"Stitching output folder not created.\")\n",
    "\n",
    "if os.path.isdir(meta_dir) == True:\n",
    "    print(f\"Metadata folder: {meta_dir} created successfully.  Move metadata files to metadata folder.\")\n",
    "\n",
    "else:\n",
    "    print(\"Metadata folder not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d317da-fc97-4dc5-954b-3b029c832bf5",
   "metadata": {},
   "source": [
    "Optional. Save these variables in a text file to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3b67a-7272-4e0c-9f13-c428cf98e4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "variables = globals()\n",
    "variable_names_to_save = ['stitch_dir', 'meta_dir', 'image_dir']\n",
    "\n",
    "with open(project_file, 'w') as file:\n",
    "    for var_name in variable_names_to_save:\n",
    "        if var_name in variables:\n",
    "            var_value = variables[var_name]\n",
    "            var_str = f'{var_name}={var_value}\\n'\n",
    "            file.write(var_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a10cf-bfc1-4e19-8781-3bdef95b2351",
   "metadata": {},
   "source": [
    "### 2.3 Shorten cycle folder names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53d27f-b922-4541-97f7-196727f1615e",
   "metadata": {},
   "source": [
    "NOTE: Running this cell permanently alters the cycle folder names.  This only needs to be run once.\n",
    "\n",
    "If the cycle folders have long names starting with the cycle numbers followed by a split character (e.g. the underscore in 'cyc001_reg001_200210_170925') this cell will shorten the folder name to everything before the first split character.\n",
    "\n",
    "Make sure to run the codeblock above before moving on to the next code block.\n",
    "\n",
    "Enter the split character in quotations.  It is usually an underscore.\n",
    "\n",
    "Note that the rest of the folder name will be deleted unless you add additional arguments to the os.rename function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149a409-5c8d-4bf1-a124-dc3f73ea8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename long source folder names\n",
    "\n",
    "split_character = simpledialog.askstring(\"Split character\", \"Enter split character\")\n",
    "print(f'Split character is {split_character}.')\n",
    "if split_character == 'None':\n",
    "    print('No input given.')\n",
    "\n",
    "else:\n",
    "    for cyc_folder in os.listdir(image_dir):\n",
    "        new_name = cyc_folder.split(split_character)\n",
    "        cycle_dir = os.path.join(image_dir, cyc_folder)\n",
    "        cycle_dir_short = os.path.join(image_dir, new_name[0])\n",
    "        new_cycle_name = os.rename(cycle_dir, cycle_dir_short)\n",
    "        if os.path.isdir(new_cycle_name) == True:\n",
    "            print(f\"{cycle_dir} renamed to {cycle_dir_short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38245002-5899-4de5-bade-2939198eb63c",
   "metadata": {},
   "source": [
    "## 3. Testing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6c160-eb44-4692-b935-701cc39c2b71",
   "metadata": {},
   "source": [
    "Before running very large image datasets, first inspect a sample of images, and then check the quality of illumination correction, stitching, and deconvolution.  Here parameters can be tested, tuned, and refined as necessary with visual inspection of a single cycle, zplane, channel combination.  Starting with the nuclear staining channel or other channels necessary for segmentation is a good idea, then make sure to assess channels with differing staining patterns and intensities.\n",
    "\n",
    "Make sure the directories are defined!\n",
    "\n",
    "The zplane and channel numbers of interest, and the pattern of the image_file name must be entered below.  The wildcard characters \"??\" are entered where the image tile numbers are so that all tiles are loaded.\n",
    "\n",
    "The cycle folder names are assumed to have been shortened and in the format \"cyc00x\".  Running the cell will prompt to enter the cycle folder of interest.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e771989-98f8-4d57-93ed-1a1ccb934243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C:/Users/smith6jt/1904_CC2B28_raw/cyc001/1_000??_Z008_CH1.tif\n",
      "Type: uint16; Min pixel: 0; Max pixel: 32121\n",
      "Set of bad pixels: []. Check if not []\n",
      "Min pixel: 0 Max pixel: 32121\n"
     ]
    }
   ],
   "source": [
    "cycle_folder = filedialog.askdirectory()\n",
    "\n",
    "zplane = 8\n",
    "channel = 1\n",
    "\n",
    "# image_file name below is derived from 1_000tt_Z0zz_CHc.tif where tt is the tile number with one leading zero, zz is the z-position with one leading zero, and c is the channel number.\n",
    "image_file = f'1_000??_Z0{str(zplane).zfill(2)}_CH{channel}.tif'\n",
    "print(f\"Using {cycle_folder}/{image_file}\")\n",
    "\n",
    "#Convert to numpy array\n",
    "im_raw = sorted(glob(os.path.join(cycle_folder, image_file)), key = alphanumeric_key)\n",
    "im = io.imread_collection(im_raw)\n",
    "im_array = np.asarray(im)\n",
    "print(f\"Type: {im_array.dtype}; Min pixel: {str(np.min(im_array))}; Max pixel: {str(np.max(im_array))}\")\n",
    "\n",
    "if np.min(im_array) != 0:\n",
    "    im_array = im_array - np.min(im_array)\n",
    "\n",
    "np_mask = np.isnan(im_array)\n",
    "nan_indices = np.where(np_mask)[0]\n",
    "\n",
    "print(f\"Set of bad pixels: {nan_indices}. Check if not []\") \n",
    "\n",
    "print(f\"Min pixel: {str(np.min(im_array))} Max pixel: {str(np.max(im_array))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f4e38-a153-4096-b862-c49cfb12f4e7",
   "metadata": {},
   "source": [
    "### 3.1 Illumination Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f084643-4951-4b69-a2cf-fe749253c27a",
   "metadata": {},
   "source": [
    "For illumination correction, we use the BaSiCPy package.  An important consideration is whether or not to calculate darkfield.  There are many more arguments for the BaSiC and autotune functions that can be manipulated as needed.  For more information see: https://github.com/peng-lab/BaSiCPy/tree/main.\n",
    "\n",
    "To reuse a set of parameters, uncomment the load_model and save_model lines while commenting out the first two lines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5144ddab-7925-477c-afc1-4e93fcfc719d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Ranges: ([0.001, 1000.0], [0.1, 10.0], [0.0, 0.07088952033878887], [0.1, 406.1394851597288])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from skimage.filters import sobel\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# Function to calculate parameter ranges for a single image\n",
    "def calculate_parameters(image):\n",
    "    # Smoothness\n",
    "    gradient_variance = np.var(sobel(image))\n",
    "    mu_range = [0.001, 1.0 / max(gradient_variance, 1e-3)]\n",
    "\n",
    "    # Flat field smoothness\n",
    "    intensity_variance = np.var(image)\n",
    "    lambda_flat_range = [0.1, min(10, 1.0 / max(intensity_variance, 1e-3))]\n",
    "\n",
    "    # Dark field\n",
    "    lower_quantile = np.percentile(image, 1)\n",
    "    alpha_range = [0, lower_quantile * 2]\n",
    "\n",
    "    # Sparse dark field\n",
    "    noise_level = np.std(image[image < lower_quantile])\n",
    "    lambda_sparse_range = [0.1, 1.0 / max(noise_level, 1e-3)]\n",
    "\n",
    "    return mu_range, lambda_flat_range, alpha_range, lambda_sparse_range\n",
    "\n",
    "# Aggregate ranges for the dataset\n",
    "def aggregate_ranges(dataset):\n",
    "    mu_all, flat_all, alpha_all, sparse_all = [], [], [], []\n",
    "\n",
    "    for image_path in dataset:\n",
    "        image = io.imread(image_path)\n",
    "        image = image / np.max(image)  # Normalize to 0-1\n",
    "        mu, flat, alpha, sparse = calculate_parameters(image)\n",
    "\n",
    "        mu_all.append(mu)\n",
    "        flat_all.append(flat)\n",
    "        alpha_all.append(alpha)\n",
    "        sparse_all.append(sparse)\n",
    "\n",
    "    # Use robust statistics (e.g., 5%-95% range)\n",
    "    mu_range = [np.min(mu_all), np.percentile(mu_all, 95)]\n",
    "    flat_range = [np.min(flat_all), np.percentile(flat_all, 95)]\n",
    "    alpha_range = [np.min(alpha_all), np.percentile(alpha_all, 95)]\n",
    "    sparse_range = [np.min(sparse_all), np.percentile(sparse_all, 95)]\n",
    "\n",
    "    return mu_range, flat_range, alpha_range, sparse_range\n",
    "\n",
    "# Example usage\n",
    "dataset = im_raw\n",
    "parameter_ranges = aggregate_ranges(dataset)\n",
    "print(\"Parameter Ranges:\", parameter_ranges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f4815-563f-466b-9cec-71b8e18f6f85",
   "metadata": {},
   "source": [
    "View the correction profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49002f3-9bd8-400a-86f2-72b5c4b8ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "variables = globals()\n",
    "variable_names_to_save = ['stitch_dir', 'meta_dir', 'image_dir']\n",
    "\n",
    "with open(project_file, 'w') as file:\n",
    "    for var_name in variable_names_to_save:\n",
    "        if var_name in variables:\n",
    "            var_value = variables[var_name]\n",
    "            var_str = f'{var_name}={var_value}\\n'\n",
    "            file.write(var_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb8bfe-5859-44cf-bac2-154bd2a5d486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu_values = []\n",
    "lam_values = []\n",
    "alpha_values = []\n",
    "lam_sparse = []\n",
    "\n",
    "for im in im_raw:\n",
    "    # Example for a single image\n",
    "    image = io.imread(im)\n",
    "\n",
    "    # Smoothness\n",
    "    gradient_variance = np.var(sobel(image))\n",
    "    mu_range = [0.001, 1.0 / max(gradient_variance, 1e-3)]\n",
    "    \n",
    "\n",
    "    # Flat field smoothness\n",
    "    intensity_variance = np.var(image)\n",
    "    lambda_flat_range = [0.1, min(10, 1.0 / max(intensity_variance, 1e-3))]\n",
    "\n",
    "    # Dark field\n",
    "    lower_quantile = np.percentile(image, 1)\n",
    "    alpha_range = [0, lower_quantile * 2]\n",
    "\n",
    "    # Sparse dark field\n",
    "    noise_level = np.std(image[image < lower_quantile])  # Assume low-intensity pixels are noise\n",
    "    lambda_sparse_range = [0.1, 1.0 / max(noise_level, 1e-3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c895c-bdee-4e4e-aae3-061b0903b591",
   "metadata": {},
   "source": [
    "## 3.2 Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05c0bb-751e-404c-a6d1-6a57a58fcabe",
   "metadata": {},
   "source": [
    "Here we first stitch the original uncorrected tiles followed by the corrected tiles.  This is accomplished using the package m2stitch.  Enter the number of rows and columns, and overlap percentage known from your data.  The \"pou\" stands for percent overlap uncertainty and is the sole parameter that can be changed to affect stitching quality.  The rows and columns functions are for generating lists corresponding to a \"snake by rows\" pattern starting at the upper left of the image.  They will need to be changed for other stitching patterns.\n",
    "\n",
    "To save and reuse stitching results, uncomment/comment out the appropriate lines.  The results are saved to the metadata folder defined above.\n",
    "\n",
    "Be sure to closely evaluate the areas of overlap for stitching quality.  The cells below allow for visualizing in this notebook and for saving to inspect elsewhere.\n",
    "\n",
    "For more information see https://github.com/yfukai/m2stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261aed6-bde7-4b27-88d9-653a11377ece",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 11  # Number of rows (height)\n",
    "m = 9 # Number of columns (width)\n",
    "overlap_percentage = 0.30\n",
    "pou = 12\n",
    "stitch_model = os.path.join(meta_dir, \"result.pkl\")\n",
    "\n",
    "# Row coordinates: each row index is repeated m times\n",
    "rows = list(chain.from_iterable(repeat(row, m) for row in range(n)))\n",
    "\n",
    "# Column coordinates: snake pattern for each row, going back and forth\n",
    "cols = list(chain.from_iterable(\n",
    "    range(m) if row % 2 == 0 else range(m - 1, -1, -1) for row in range(n)\n",
    "))\n",
    "result_df, _ = stitch_images(im_array, rows, cols, initial_ncc_threshold = 0, overlap_percentage=overlap_percentage, pou=pou)\n",
    "result_df.to_pickle(stitch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ee940-8ef9-4ca9-90f2-c0400defdd26",
   "metadata": {},
   "source": [
    "If the cell above has already been run to create a stitching model, run the cell below to apply it to the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df33a5-9791-4448-85c4-f28d4e3ad7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_model = os.path.join(meta_dir, \"result.pkl\")\n",
    "\n",
    "result_df=pd.read_pickle(stitch_model)\n",
    "\n",
    "result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "\n",
    "size_y = im_array.shape[1]\n",
    "size_x = im_array.shape[2]\n",
    "\n",
    "stitched_image_size = (\n",
    "    result_df[\"y_pos2\"].max() + size_y,\n",
    "    result_df[\"x_pos2\"].max() + size_x,\n",
    ")\n",
    "stitched_image = np.zeros_like(im_array, shape=stitched_image_size)\n",
    "for i, row in result_df.iterrows():\n",
    "    stitched_image[\n",
    "        row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "        row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "    ] = im_array[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db018213-9ff0-4657-9ec3-02c6e4677f7b",
   "metadata": {},
   "source": [
    "Visualize the result of stitching the original tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228d715-e449-4611-8ab7-32ca159a5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_image_re = exposure.rescale_intensity(stitched_image, in_range=(np.min(stitched_image), np.max(stitched_image)), out_range=(0, 65535)).astype(np.uint16)\n",
    "fig, axes = plt.subplots(figsize=(24, 18))\n",
    "im = axes.imshow(stitched_image_re, vmax=55000)\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0990e-79ca-4e54-a2a3-42862d01e6cf",
   "metadata": {},
   "source": [
    "Save the stitched image if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb846537-be67-4824-a7d7-3d3844b52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_image_2 = exposure.rescale_intensity(stitched_image, in_range=(np.min(stitched_image), np.max(stitched_image)), out_range=(0, 65535)).astype(np.uint16)\n",
    "raw_image_file_path = os.path.join(meta_dir, \"test_original.tif\") \n",
    "imsave(raw_image_file_path, stitched_image_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad4d25-24c2-4c67-b609-3e144d681bd4",
   "metadata": {},
   "source": [
    "Reuse the stitching model to stitch the corrected tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984ccb8-c7a8-4511-8af8-0a917f922253",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_model = os.path.join(meta_dir, \"result.pkl\")\n",
    "result_df=pd.read_pickle(stitch_model)\n",
    "result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "\n",
    "size_y = images_transformed.shape[1]\n",
    "size_x = images_transformed.shape[2]\n",
    "\n",
    "stitched_image_size = (\n",
    "    result_df[\"y_pos2\"].max() + size_y,\n",
    "    result_df[\"x_pos2\"].max() + size_x,\n",
    ")\n",
    "stitched_image_basic = np.zeros_like(images_transformed, shape=stitched_image_size)\n",
    "for i, row in result_df.iterrows():\n",
    "    stitched_image_basic[\n",
    "        row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "        row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "    ] = images_transformed[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7325c3-1562-42b8-9b03-7647c8f86061",
   "metadata": {},
   "source": [
    "Visualize the result of stitching the corrected tiles.  Comment/uncomment the coordinates to crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d64ca7-9e63-44dc-9f33-6b032a74ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_image_basic_re = exposure.rescale_intensity(stitched_image_basic, in_range=(np.min(stitched_image_basic), np.max(stitched_image_basic)), out_range=(0, 65535)).astype(np.uint16)\n",
    "# x1 = 6000\n",
    "# x2 = 8000\n",
    "# y1 = 0000\n",
    "# y2 = 3000\n",
    "fig, axes = plt.subplots(figsize=(24, 18))\n",
    "# im = axes.imshow(stitched_image_basic[y1:y2,x1:x2])\n",
    "im = axes.imshow(stitched_image_basic_re, vmax=55000)\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d052bc5-3940-4aa9-be44-e32a92ca4fbd",
   "metadata": {},
   "source": [
    "Save the corrected stitched image if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79273c7-bd3f-4e74-8fa8-984a34f5020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_image_basic_re = exposure.rescale_intensity(stitched_image_basic, in_range=(np.min(stitched_image_basic), np.max(stitched_image_basic)), out_range=(0, 65535)).astype(np.uint16)\n",
    "result_image_file_path = os.path.join(meta_dir, \"test_corrected.tif\") \n",
    "imsave(result_image_file_path, stitched_image_basic_re, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c20b6c-76de-4d16-8b47-d9ce92100233",
   "metadata": {},
   "source": [
    "Before testing deconvolution, you must correct and stitch an entire z-stack.  For this you can run the cells above for each image in the stack, or use B_IllumCor_Stitching_Decon.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52a231-4fc2-455d-abfa-0f9e97c6eb3a",
   "metadata": {},
   "source": [
    "## 3.3 Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e143f9c-2371-46bb-abc4-eed1fe016590",
   "metadata": {},
   "source": [
    "The following cell has multiple parameters related to the microscope used to aquire the images and the images themselves.  Once these are input, the testing is primarily to tune the number of iterations/stop_crit necessary to get good results.  The damping and hist_clip further can improve results.  There is no need to supply a point-spread function.  Finally, finding the optimal use of computing resources on GPU or CPU is accomplished via the max_GPU and max_CPU parameters.  There is no limit to image size.  If the images are too large to fit in the specified memory maximums, the will be split into blocks and processed sequentially.\n",
    "\n",
    "Be sure the MATLAB Runtime v9.5 (R2018, 64-bit) is installed.  Download for free here: http://www.mathworks.com/products/compiler/mcr/index.html. Reboot your computer after install.  \n",
    "\n",
    "The image_dir and stitch_dir definitions used previously will be again used here, and a new folder will be created to save the deconvolved images.  \n",
    "\n",
    "The original deconvolution program was for lightsheet images and modified to use with widefield fluorescence.  See https://www.nature.com/articles/s41598-019-53875-y \n",
    "\n",
    "Output will be written to the terminal.  Check that the first image stack is processed without error.  If there is an \"Maximum variable size allowed on the device is exceeded.\" error, then restart the kernel, decrease the max_GPU or max_CPU parameter, rerun the decon function cell, and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6c3b5-66b0-4fb9-bfc3-6e10c21b2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_cycles = 1\n",
    "dec_channels = 1\n",
    "\n",
    "# pixel size in xy dimension (nanometers)\n",
    "xy_vox = 377\n",
    "# pixel size in z dimension (nanometers)\n",
    "z_vox = 1500\n",
    "# Number of iterations of Lucy-Richardson algo before stopping unless stop_crit is met first\n",
    "iterations = 25\n",
    "# Microscope objective numerical aperture\n",
    "mic_NA = 0.75\n",
    "# Refractive index of tissue being imaged\n",
    "tissue_RI = 1.3\n",
    "# Opening size in millimeters of objective aperture\n",
    "slit_aper = 6.5\n",
    "# Focal length in millimeters of objective\n",
    "f_cyl = 1\n",
    "# Used to reduce noise.  Increase value for noisy images. (0-10)\n",
    "damping = 0\n",
    "# If set, the deconvolved images will be clipped by this percent for max and min values, and then scaled to full range of bit depth. (0-5)\n",
    "hist_clip = 0.010\n",
    "# Percent change between iterations to use as criteria to stop deconvolution.\n",
    "stop_crit = 5.00\n",
    "# Enter 1 to perform on GPU, 0 to use CPU\n",
    "GPU = 1\n",
    "# Percent maximum GPU memory to use if GPU = 1\n",
    "max_GPU = 45\n",
    "# Percent maximum RAM to use if GPU = 0\n",
    "max_CPU = 20\n",
    "if GPU == 1:\n",
    "    max_block=max_GPU\n",
    "elif GPU == 0:\n",
    "    max_block=max_CPU\n",
    "# The excitation and emission wavelength in nanometers\n",
    "ex = 358\n",
    "em = 461\n",
    "\n",
    "decon_exe = os.path.join(os.path.dirname(image_dir), \"LsDeconv.exe\")\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "source = os.path.join(stitch_dir, f\"cyc{str(dec_cycles).zfill(2)}\", f\"CH{str(dec_channels)}\")\n",
    "dest = os.path.join(decon_dir, f\"cyc{str(dec_cycles).zfill(2)}\", f\"CH{str(dec_channels)}\")\n",
    "os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(ex), str(em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "gc.collect()\n",
    "try:\n",
    "    os.rename(os.path.join(source, 'deconvolved'), os.path.join(dest, 'deconvolved'))\n",
    "except (FileNotFoundError):\n",
    "    print(\"Reduce max memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a6de1-9bd3-47ad-8e56-d881d6828a26",
   "metadata": {},
   "source": [
    "The following cell will compare the original to the deconvolved image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2281a00-4955-44a1-b044-88b12986ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the cycle, channel, and z-plane for the image you want to evaluate.\n",
    "c = 5\n",
    "ch = 3\n",
    "z = 8\n",
    "\n",
    "# Crop the image by entering the x and y coordinates below.\n",
    "x1 = 400\n",
    "x2 = 1000\n",
    "y1 = 600\n",
    "y2 = 1200\n",
    "\n",
    "source_image = imread(os.path.join(stitch_dir, f\"cyc{str(c).zfill(2)}\", f\"CH{str(ch)}\", f\"{str(z).zfill(2)}.tif\"))\n",
    "dest = os.path.join(stitch_dir.replace('_BaSiC_Stitched', '_Decon'), f\"cyc{str(c).zfill(2)}\", f\"CH{str(ch)}\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 18))\n",
    "im = axes[0].imshow(source_image[x1:x2,y1:y2])\n",
    "fig.colorbar(im, shrink=0.5, ax=axes[0])\n",
    "axes[0].set_title(\"Original\")\n",
    "decon_image = imread(os.path.join(dest, 'deconvolved', f\"deconv_0000{str(z).zfill(2)}.tif\"))\n",
    "im = axes[1].imshow(decon_image[x1:x2,y1:y2])\n",
    "fig.colorbar(im, shrink=0.5, ax=axes[1])\n",
    "axes[1].set_title(\"Deconvolved\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8267e1a-a6d9-4cd3-a128-48554ed9c66c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You may now use the optimized parameters in the next notebook to process large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa4f09-712c-47d5-ab1d-c5cacf83edde",
   "metadata": {},
   "source": [
    "## 4 FIJI Clij2 plugin - EDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373bd03-dfcc-444a-ad9a-4426180dc486",
   "metadata": {},
   "source": [
    "The following section connects this notebook with a local installation of FIJI and a Clij2 plugin to run an Extended Depth of Focus (EDF) projection along the deconvolved image stack.  The image calculation is done on the GPU for efficient processing.  In the next cell enter the amount of memory (no more than 80% of system RAM is a good rule of thumb) to allow for the computation.  Also, enter the name of the GPU, and the parameters for the EDF calculation.  A new folder will be created for the results, and the image can be inspected in another program and in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61775b7-3e9a-4e9f-b1f0-1a3e28efe96d",
   "metadata": {},
   "source": [
    "### 4.1 EDF on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e88d94-1767-4ad9-9125-d8cfe2dcf9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ij_mem = 40\n",
    "edf_cycles = 1\n",
    "edf_channels = 1\n",
    "GPU_name = \"NVIDIA RTX A4500\"\n",
    "radius_x = 5.0\n",
    "radius_y = 5.0\n",
    "sigma = 20.0\n",
    "\n",
    "scyjava.config.add_option(f'-Xmx{str(ij_mem)}g')\n",
    "ij = imagej.init('C:/Users/smith6jt/Fiji.app')\n",
    "\n",
    "macro = \"\"\"\n",
    "#@ File in_folder\n",
    "#@ String device\n",
    "#@ File out_folder\n",
    "#@ Integer radius_x\n",
    "#@ Integer radius_y\n",
    "#@ Integer sigma\n",
    "\n",
    "File.openSequence(in_folder);\n",
    "run(\"CLIJ2 Macro Extensions\", \"cl_device=[\" + device + \"]\");\n",
    "Ext.CLIJ_clear();\n",
    "image1 = \"deconvolved\";\n",
    "Ext.CLIJ2_push(image1);\n",
    "image2 = \"extended_depth_of_focus_variance_projection\";\n",
    "radius_x = 5.0;\n",
    "radius_y = 5.0;\n",
    "sigma = 20.0;\n",
    "Ext.CLIJ2_extendedDepthOfFocusVarianceProjection(image1, image2, radius_x, radius_y, sigma);\n",
    "Ext.CLIJ2_pull(image2);\n",
    "selectImage(image1);\n",
    "close();\n",
    "selectImage(image2);\n",
    "saveAs(\"Tiff\", out_folder + File.separator + \"EDF.tif\");\n",
    "\"\"\"\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "edf_dir = decon_dir.replace('_Decon', '_EDF')\n",
    "edf_source = os.path.join(decon_dir, f\"cyc{str(edf_cycles).zfill(2)}\", f\"CH{str(edf_channels)}\", \"deconvolved\")\n",
    "edf_dest = os.path.join(edf_dir, f\"cyc{str(edf_cycles).zfill(2)}\", f\"CH{str(edf_channels)}\")\n",
    "os.makedirs(edf_dest, exist_ok=True)\n",
    "\n",
    "args ={'in_folder': edf_source, \"cl_device\" : GPU_name, \"out_folder\" : edf_dest, \"radius_x\" : 5.0, \"radius_y\" : 5.0, \"sigma\" : 20.0}\n",
    "ij.py.run_macro(macro, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a141e-3b4f-44c3-a7fa-72ea1480cfb6",
   "metadata": {},
   "source": [
    "### 4.2 EDF comparison with deconvolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627d4c8-90ff-4871-958a-63cd59b71981",
   "metadata": {},
   "source": [
    "Visualize the results with periodic z-planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8933b-b171-4352-8ec4-e2301ca4510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decon_stack = sorted(glob(os.path.join(edf_source, f\"deconv_0000??.tif\")), key=alphanumeric_key)\n",
    "decon_stack = io.imread_collection(decon_stack)\n",
    "decon_image = np.asarray(decon_stack)\n",
    "edf_result = imread(os.path.join(edf_dest, \"EDF.tif\"))\n",
    "\n",
    "x1 = 2400\n",
    "x2 = 3000\n",
    "y1 = 2000\n",
    "y2 = 3000\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 8))\n",
    "im = axes[0,0].imshow(decon_image[6][x1:x2,y1:y2])\n",
    "axes[0,0].set_title(\"decon_z007\")\n",
    "im = axes[0,1].imshow(decon_image[7][x1:x2,y1:y2])\n",
    "axes[0,1].set_title(\"decon_z008\")\n",
    "im = axes[0,2].imshow(decon_image[8][x1:x2,y1:y2])\n",
    "axes[0,2].set_title(\"decon_z009\")\n",
    "im = axes[1,0].imshow(decon_image[9][x1:x2,y1:y2])\n",
    "axes[1,0].set_title(\"decon_z010\")\n",
    "im = axes[1,1].imshow(decon_image[10][x1:x2,y1:y2])\n",
    "axes[1,1].set_title(\"decon_z011\")\n",
    "im = axes[1,2].imshow(edf_result[x1:x2,y1:y2])\n",
    "axes[1,2].set_title(\"EDF_var_x5y5_sigma20\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01df92f-7e3f-4d05-a4ad-60f77346ff68",
   "metadata": {},
   "source": [
    "Visualize the results as a full image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd005e22-c399-4504-97cd-5e5b546b03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_result = imread(os.path.join(edf_dest, \"EDF.tif\"))\n",
    "fig, axes = plt.subplots(figsize=(24, 18))\n",
    "im = axes.imshow(edf_result)\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60c82d-49c2-4f35-9626-a4025fd3d6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868d2f3-554e-46e3-ad8a-0cc4042c7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import window\n",
    "\n",
    "\n",
    "\n",
    "x1=2000\n",
    "x2=7000\n",
    "y1=2000\n",
    "y2=7000\n",
    "\n",
    "\n",
    "# power_im1 = calculate_power_spectrum(signal_image_tiff)\n",
    "# power_im_norm1 = calculate_power_spectrum(signal_image_tiff, normalize_by_mean=True)\n",
    "# frequencies1, power_spectrum_1d1 = calculate_summed_power(power_im1)\n",
    "# f_k1, profile1 = calculate_radial_average(signal_image_tiff, bin_size=2)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "ax = axes.ravel()\n",
    "ax[0].set_title(\"Original image\")\n",
    "ax[0].imshow(signal_image_tiff, cmap='viridis', vmax=10000)\n",
    "ax[1].set_title(\"Power Spectrum\")\n",
    "ax[1].imshow(np.log(power_im1), cmap='magma')\n",
    "ax[2].set_title(\"Power Spectrum Norm\")\n",
    "ax[2].imshow(np.log(power_im_norm1), cmap='magma')\n",
    "\n",
    "ax[3].set_title(\"Subtracted Image\")\n",
    "ax[3].imshow(signal_image, cmap='viridis', vmax=10000)\n",
    "ax[4].set_title(\"Subtracted Power Spectrum\")\n",
    "ax[4].imshow(np.log(power_im), cmap='magma')\n",
    "ax[5].set_title(\"Subtracted Power Spectrum Norm\")\n",
    "ax[5].imshow(np.log(power_im_norm), cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2a61a-6f3c-4e73-a223-5b76de4b1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(f_k1, profile1, label='Power Spectrum')\n",
    "plt.ylabel(\"Average Power (log scale)\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.title('2D Power Spectrum with Logarithmic Scale')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7741d-cb26-47b2-af00-96c571bf86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies1, power_spectrum_1d1, label='Power Spectrum')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Total Power (log scale)')\n",
    "plt.title('1D Power Spectrum with Logarithmic Scale')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263947de-552f-42e6-82ab-32e5a7a03d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies, power_spectrum_1d, label='Subtracted Power Spectrum')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Total Power (log scale)')\n",
    "plt.title('Subtracted 1D Power Spectrum with Logarithmic Scale')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80380a-f1ad-47a1-b4e8-04f283036b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
