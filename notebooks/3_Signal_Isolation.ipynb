{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ce0a89-8797-4eb9-b0fc-243aff74bdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow, imsave\n",
    "import os\n",
    "import numpy as np\n",
    "import stackview\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data, io\n",
    "from skimage import morphology\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "current_dateTime = datetime.now()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def ini_params(images, imageb, Pixel_Cutoff:int=0, Blank_Percentile:float=0.0):\n",
    "\n",
    "    blank_image = np.clip(imageb, Pixel_Cutoff, 65535)\n",
    "    blank_image[blank_image <= Pixel_Cutoff] = 0\n",
    "    \n",
    "    signal_image = images - (np.minimum(images, blank_image * Blank_Percentile))\n",
    "    \n",
    "    return signal_image\n",
    "\n",
    "def make_mask(blank_im, disk1:int=4, disk2:int=1):\n",
    "    blank_smoothed = morphology.white_tophat(blank_im, morphology.disk(disk1))\n",
    "    blank_threshold = filters.threshold_otsu(blank_smoothed)\n",
    "    autofluorescent_mask = blank_im > blank_threshold\n",
    "\n",
    "    autofluorescent_mask = morphology.binary_closing(autofluorescent_mask, morphology.disk(disk2))\n",
    "    return autofluorescent_mask.astype(np.uint8)\n",
    "\n",
    "def find_gauss(signal_image2, sigma_value:int=10):\n",
    "    signal_image = signal_image2 * 1.01\n",
    "    blank = filters.gaussian(signal_image, sigma=sigma_value, preserve_range=True)\n",
    "    return blank\n",
    "\n",
    "def clipped_blank(blank_image, Gauss_low:int = 0, Gauss_high:int = 65535):\n",
    "    blank_image2 = blank_image * 1.01\n",
    "    # blank2 = np.clip(blank_image, Gauss_low, np.max(blank_image))\n",
    "    blank_image2[Gauss_low >= blank_image2] = 0  \n",
    "    blank_image2[blank_image2 >= Gauss_high] = 0\n",
    "    return blank_image2\n",
    "\n",
    "def final_factor(sig_im, bl, low, high, Gauss_Percentile:float=0.2):\n",
    "\n",
    "    bl[low >= bl] = 0  \n",
    "    bl[bl >= high] = 0\n",
    "\n",
    "    signal_im2 = sig_im - (np.minimum(sig_im, bl * Gauss_Percentile))\n",
    "    return signal_im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a83960-66b4-4518-97f3-3e0aa5123de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter sample ID portion of filename:\n",
    "sample_id = '20_06_N2_R1'\n",
    "\n",
    "# Enter directory path:\n",
    "path = 'Z:/Processed_CODEX/Misc/Intermediate_data/'\n",
    "\n",
    "sample = sample_id + '_Processed'\n",
    "\n",
    "# The single-marker images after registration in VALIS are in a folder named by sample ID and _Registered.  This creates folders for ImageJ-processed images, notebook-processed images and a folder for parameter .txt files. \n",
    "sample_base = sample.replace('_Registered', '_Processed')\n",
    "os.makedirs(path + sample_base, exist_ok=True)\n",
    "os.makedirs(path + sample_base + '/Processing_parameters', exist_ok=True)\n",
    "os.makedirs(path + sample_base + '/ImageJ', exist_ok=True)\n",
    "\n",
    "image_folder = path + sample_id + '_Registered/'\n",
    "out_folder = path + sample_id + '_Processed/'\n",
    "\n",
    "# seg_mask = imread(image_folder + sample_id +'_DAPI_segmentation.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1207ad4-7a57-456e-8c47-b4d92e17cf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a013d65fbb24e9d933f904fca349ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(interactive(children=(IntSlider(value=0, description='Pixel_Cutoff', max=50000, step=1000), Flo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell allows the user to choose which blank channel to use (BlankID) and determine how much, if any, blank image to subtract(Blank_Percentile).  It also allows for only subtracting a range of pixel values (Pixel_Cutoff).  Use these values in the next cell.\n",
    "# For each marker, enter the name of the image file without the extension for signal_channel.  Then change the letter of bl_CH to match \n",
    "signal_channel = 'CD21'\n",
    "\n",
    "# Do not change these\n",
    "params_filename = out_folder + 'Processing_parameters/' + signal_channel + '_param.txt'\n",
    "signal_image_tiff = imread(image_folder + signal_channel + '.tif')\n",
    "\n",
    "# Change bl_CH to a, b, or c according to the channel that marker was imaged on i.e. if marker is CH3, the last letter of both blanks should be 'b', CH4 should be 'c'.  For CH2 markers, the blank channels often do not match the background autofluorescence well and can also not be suitable to use at all, so a suitable 'b' or 'c' blank should be chosen.\n",
    "# Change bl_int to 13 or 1 to use a blank channel.  Blank 13 generally has photobleached autofluorescent signal compared with Blank 1, and generally removes more diffuse background.  Sometimes the images from cycles earlier in the run will match closer to blank1 while those later will match closer to blank13.\n",
    "\n",
    "bl_CH = 'b'\n",
    "bl_int = str(1)\n",
    "\n",
    "# Do not change these\n",
    "blankID = 'Blank' + bl_int + bl_CH\n",
    "blank_image_tiff = imread(image_folder + blankID + '.tif')\n",
    "\n",
    "# Sometimes blurring before subtraction can help.  Uncomment to apply.  Adjust sigma to control radius(strength) of blurring.\n",
    "blank_image_tiff = filters.gaussian(blank_image_tiff, sigma=1, preserve_range=True)\n",
    "# signal_image_tiff = filters.gaussian(signal_image_tiff, sigma=1, preserve_range=True)\n",
    "\n",
    "# This prints the current marker channel selected for subtraction.\n",
    "print(signal_channel)\n",
    "\n",
    "#This first stackview.interact function is for viewing the effects of subtraction on a close-up portion of the image.  Adjust coordinates to determine the close-up; usually just the first digit of x2 and y2.  To assess subtraction, first slowly move the Blank_Percentile slider while noting if autofluorescent structures only are getting dimmer.  Continue until none of these remain while noting if marker signal is being diminished.  Then, slowly move the other slider until signal is brightest without reintroducing autofluorescence/noise.  Once values of Blank_Percentile and Pixel_Cutoff are found, use them for the next stackview.interact to see how they look on the entire image.\n",
    "\n",
    "x1 = 2000\n",
    "x2 = 7000\n",
    "y1 = 2000\n",
    "y2 = 7000\n",
    "\n",
    "# Adjust zoom_factor to fit the image to your screen.  The other values can be adjusted as needed.\n",
    "stackview.interact(ini_params, signal_image_tiff[x1:x2,y1:y2], blank_image_tiff[x1:x2,y1:y2], zoom_factor=0.4, colormap = 'viridis', min_value=0, max_value=50000, step=1000)\n",
    "\n",
    "# Comment out the function above and uncomment the next function (CTRL + /) and check the values determined above.  Repeat this process as necessary.\n",
    "\n",
    "# stackview.interact(ini_params, signal_image_tiff, blank_image_tiff, zoom_factor=0.1, colormap = 'viridis', min_value=0, max_value=50000, step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "165b8c55-1aa6-4a82-92af-fda100d16b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell performs the subtraction with values determined above.  The lines that are commented out can be used to subtract another blank channel (blank_image_2) and perform gaussian blur.\n",
    "# If no subtraction was necessary, enter 0 for both and then go to the save cell.\n",
    "\n",
    "# Enter Pixel_Cutoff from above:\n",
    "blank_clip_factor = 16000\n",
    "\n",
    "# Enter Blank_Percentile from above:\n",
    "background_scale_factor = 0.9\n",
    "\n",
    "blank_image = np.clip(blank_image_tiff, blank_clip_factor, blank_image_tiff.max())\n",
    "blank_image[blank_image <= blank_clip_factor] = 0\n",
    "\n",
    "signal_image = signal_image_tiff - (np.minimum(signal_image_tiff, blank_image * background_scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f44f5341-93c0-4458-91ab-4922498249b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4e25fd0e284dfcb7d57ebaafb5c86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(interactive(children=(IntSlider(value=0, description='Pixel_Cutoff', max=50000, step=1000), Flo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(signal_channel)\n",
    "bl_CH2 = 'c'\n",
    "bl_int2 = str(13)\n",
    "\n",
    "# Do not change these\n",
    "blankID2 = 'Blank' + bl_int2 + bl_CH2\n",
    "# blankID2 = 'CD15'\n",
    "blank_image_tiff_2 = imread(image_folder + blankID2 + '.tif')\n",
    "blank_image_tiff_2 = filters.gaussian(blank_image_tiff_2, sigma=1, preserve_range=True)\n",
    "\n",
    "x1 = 2000\n",
    "x2 = 9000\n",
    "y1 = 2000\n",
    "y2 = 9000\n",
    "\n",
    "# Adjust zoom_factor to fit the image to your screen.  The other values can be adjusted as needed.\n",
    "# stackview.interact(ini_params, signal_image[x1:x2,y1:y2], blank_image_tiff_2[x1:x2,y1:y2], zoom_factor=0.2, colormap = 'viridis', min_value=0, max_value=50000, step=1000)\n",
    "\n",
    "# Comment out the function above and uncomment the next function (CTRL + /) and check the values determined above.  Repeat this process as necessary.\n",
    "stackview.interact(ini_params, signal_image, blank_image_tiff_2, zoom_factor=0.1, colormap = 'viridis', min_value=0, max_value=50000, step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "574ed834-0491-4509-8de9-32d5c9b77c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blank_clip_factor_2 = 9000\n",
    "background_scale_factor_2 = 0.4\n",
    "blank_image_2 = np.clip(blank_image_tiff_2, blank_clip_factor_2, blank_image_tiff_2.max())\n",
    "blank_image_2[blank_image_2 <= blank_clip_factor_2] = 0\n",
    "signal_image = signal_image - (np.minimum(signal_image, blank_image_2 * background_scale_factor_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e39a6-f945-4160-b0fc-9b8e623982cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If no other changes need to be made, go to the cells to view and save.\n",
    "# Sometimes it is helpful to subtract the gaussian of an image to remove patterns of intensity.  This stackview.interact helps to find the optimal sigma value for blurring.\n",
    "stackview.interact(find_gauss, signal_image, zoom_factor=0.1, colormap = 'viridis', min_value=0, max_value=60, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c93bd2-830c-46ff-81f6-70c35607712f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter the sigma value to perform the blurring.\n",
    "sigma = 20\n",
    "blank = filters.gaussian(signal_image, sigma=sigma, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb33ea8-a915-4c91-ae68-ec89231032a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell allows the user to only apply a range of pixel values to the gaussian subtraction.  Run after performing the gaussian blur in the cell above.\n",
    "\n",
    "# stackview.interact(clipped_blank, blank[x1:x2,y1:y2], zoom_factor=0.5, colormap = 'viridis', continuous_update=True, display_min = 0, display_max = None, min_value=0, max_value=np.max(blank), step=100)\n",
    "\n",
    "stackview.interact(clipped_blank, blank, zoom_factor=0.1, colormap = 'viridis', continuous_update=True, display_min = 0, display_max = None, min_value=0, max_value=np.max(blank), step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c699d65e-f50e-4756-a286-aef8da0ae3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543174cb9f254c42af18b232cfe86ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(interactive(children=(FloatSlider(value=0.0, description='Gauss_Percentile', max=10.0), Output(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell allows the user to determine how much subtraction to do, similar to Blank_Percentile above.  Enter the Gauss_Cutoff values from the cell above.\n",
    "\n",
    "stackview.interact(final_factor, signal_image, blank,5500,14431, colormap = 'viridis', display_max = None, zoom_factor=.1)\n",
    "\n",
    "# stackview.interact(final_factor, signal_image[x1:x2,y1:y2], blank[x1:x2,y1:y2], 0,4700, colormap = 'viridis', display_max = None, zoom_factor=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "837a306b-b446-438e-b47a-3df5588825ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell performs the gaussian subtraction.  Note that the image is renamed from signal_image to signal_image2 so saving and viewing either image can be changed by adding/removing the '2' below.\n",
    "\n",
    "# Enter Gauss_Percentile for s_image_factor:\n",
    "s_image = signal_image\n",
    "s_image_factor = 0.4\n",
    "\n",
    "# Enter Gauss_Cutoff for blank_factor:\n",
    "g_low = 5300\n",
    "g_high = 15528\n",
    "blank[g_low >= blank] = 0  \n",
    "blank[blank >= g_high] = 0\n",
    "\n",
    "signal_image2 = s_image - (np.minimum(s_image, blank * s_image_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103ac8a-451f-4d54-a9e6-97b454bfc44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is for checking the image before saving.  Add or remove the '2' after signal_image to view the first or second (typically gaussian subtracted) image.\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(25, 25))\n",
    "im = axes.imshow(signal_image,)\n",
    "fig.colorbar(im, ax=axes, shrink=.65)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d761a62d-f5ee-4137-91f6-8e8142a910dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Even with this process, it may be that certain markers should be excluded.  Manually create a \"failed markers\" file to list these and save it in the 'Processing_parameters' folder.\n",
    "# This cell saves the image and the parameters used.  Add or remove the '2' as necessary.  The next steps in FIJI should be saved as well.  For now, FIJI: Plugins>Macros>Record to record all steps and copy/paste to params file.\n",
    "\n",
    "imsave(out_folder + signal_channel + '.tif', signal_image)\n",
    "\n",
    "# Anything here will be added to .txt file:\n",
    "Notes = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# Get all variables in the global scope\n",
    "variables = globals()\n",
    "variable_names_to_save = ['current_dateTime', 'signal_channel', 'blankID', 'blank_clip_factor', 'background_scale_factor', 'blankID2', 'blank_clip_factor_2', 'background_scale_factor_2', 'sigma', 'g_low', 'g_high', 's_image_factor', 'blank_factor', 'Notes']\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(params_filename, 'w') as file:\n",
    "    # Iterate over each variable name to save\n",
    "    for var_name in variable_names_to_save:\n",
    "        # Check if the variable exists in the global scope\n",
    "        if var_name in variables:\n",
    "            # Get the variable value\n",
    "            var_value = variables[var_name]\n",
    "            # Convert the variable to a string representation\n",
    "            var_str = f'{var_name}: {repr(var_value)}\\n'\n",
    "            # Write the variable string to the file\n",
    "            file.write(var_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e7687-574f-4987-8806-4541dfe6b4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a04f701-6464-427f-b1a6-7057e1b4718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell merges all the images together.  May have to input pixel sizes manually. \n",
    "\n",
    "# Enter sample ID portion of filename:\n",
    "sample_id = '20_06_N1_R2'\n",
    "\n",
    "# Enter directory path:\n",
    "path = 'Z:/Processed_CODEX/HubMap_LymphNode/'\n",
    "\n",
    "sample = sample_id + '_Processed/'\n",
    "\n",
    "folder = sample + 'ImageJ/'\n",
    "\n",
    "pixelsize = 0.3774\n",
    "channel_names = []\n",
    "\n",
    "for file in glob(path +sample+'*.tif'):\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    # print(file_name)\n",
    "    file_name = file_name.split('.')\n",
    "    channel_name = file_name[0]\n",
    "    # print(channel_name)\n",
    "    channel_names.append(channel_name)\n",
    "\n",
    "image = imread(path +sample+'*.tif').astype(np.uint16)\n",
    "\n",
    "imsave('C:/Users/smith6jt/QuPath_Projects/Lymph_Node/Images/'+sample_id+'.tif', image, imagej=True, resolution=(1/pixelsize, 1/pixelsize), resolutionunit='MICROMETER', metadata={'axes': 'CYX', 'Labels': channel_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c5a67-aae9-447c-87ae-9abcb8980fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function may be used in place of ini_params above to assess how subtraction affects signal to noise.  Must have a binary segmentation file.\n",
    "# def ini_params_SNR(images, imageb, seg_mask, blclfa:int=0, bckscfa:float=.0):\n",
    "\n",
    "#     blank_image = np.clip(imageb, blclfa, 65535)\n",
    "#     blank_image[blank_image <= blclfa] = 0\n",
    "\n",
    "#     signal_image = images - (np.minimum(images, blank_image * bckscfa))\n",
    "#     seg_mask = measure.label(seg_mask, return_num=True, background=0)\n",
    "#     properties = measure.regionprops(seg_mask[0], intensity_image=signal_image)\n",
    "#     statistics = {\n",
    "   \n",
    "#     'area':       [p.area               for p in properties if p.area<800],\n",
    "#     'mean':       [p.mean_intensity     for p in properties if p.area<800]\n",
    "#     }\n",
    "#     df = pd.DataFrame(statistics)\n",
    "    \n",
    "#     MFI = np.asarray(df['mean'])\n",
    "#     aX = MFI.flatten()\n",
    "#     # compute 20 largest values in aX\n",
    "#     top20 = np.sort(aX)[-20:]\n",
    "#     # compute the mean of bottom 10th percentile of aX\n",
    "#     btm10 = np.sort(aX)[:int(len(aX)*0.1)]\n",
    "#     top20btm10 = np.mean(top20)/np.mean(btm10)\n",
    "    \n",
    "#     print('SNR is ' + str(top20btm10)) \n",
    "#     print(df.describe())\n",
    "#     return signal_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
