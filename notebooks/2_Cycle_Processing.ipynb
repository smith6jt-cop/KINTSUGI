{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de152bce-3aae-4e74-b337-ff06e0345601",
   "metadata": {},
   "source": [
    "# KINTSUGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9b613-22fc-40c7-a4a3-e5f0b1cb9f73",
   "metadata": {},
   "source": [
    "## In the following notebook you will use the parameters found in A_Evaluation&Testing.ipynb to correct and stitch entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20908051-79d7-4e17-8725-587ca5084c2b",
   "metadata": {},
   "source": [
    "### 1. Import packages. *This must be done every time the notebook is started or restarted.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743639-2916-4aaa-bcd4-e235c0bbc47e",
   "metadata": {},
   "source": [
    "Import these packages. Run cells using Ctrl+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b61c7f-445a-466f-a3d3-dfefa0d45258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import os as os\n",
    "from tqdm.notebook import tqdm\n",
    "import cupy as cp\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import KCorrect\n",
    "from Kstitch.stitching import stitch_images\n",
    "from glob import glob\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "import shutil\n",
    "import numpy as np\n",
    "from skimage.io import imread \n",
    "from skimage.io import imsave\n",
    "from skimage import io\n",
    "from skimage import util\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from itertools import chain, repeat\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import imagej, scyjava\n",
    "import logging\n",
    "current_dateTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2ab6-e1f7-45b0-96c2-a2a691807caf",
   "metadata": {},
   "source": [
    "### 2. Define directory paths. *This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879430d-d043-4d6b-9e94-018b36cc7c80",
   "metadata": {},
   "source": [
    "Below are three ways to get the required paths to input, output, and meta folders.  The first is where they can be entered manually.  The second-fourth simply asks for the location of each.  The third reads from the project_data.txt file created in the first notebook and appends the variables to the global variable list.\n",
    "\n",
    "In each of these methods, a text file to store correction parameters is defined.\n",
    "\n",
    "Choose only one method: A, B, or C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d14b24-d405-4382-8199-698348661149",
   "metadata": {},
   "source": [
    "### 2.1 Method A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2736065-d891-45e8-a56e-8190ce6028e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_raw.\n",
      "Stitching folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched.\n",
      "Meta folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_meta.\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/Users/smith6jt/KINTSUGI\"\n",
    "image_dir =\"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_raw\"\n",
    "stitch_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\"\n",
    "meta_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_meta\"\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Image folder is {image_dir}.\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c178c6-981c-47c4-9014-46acb9d170dd",
   "metadata": {},
   "source": [
    "### 2.2 Method B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117013a-6e2e-4107-8b2e-96f2f6a9ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter image input directory.\n",
    "image_dir = filedialog.askdirectory()\n",
    "print(f\"Image folder is {image_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d3259-7c77-48e9-b524-e57a43466c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter stitching output directory.\n",
    "stitch_dir = filedialog.askdirectory()\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a42eae-1858-4baa-842f-9c5bce0de580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the metadata directory.\n",
    "stitch_dir = filedialog.askdirectory()\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bdf412-2342-4d4e-a085-969767c20df2",
   "metadata": {},
   "source": [
    "### 2.3 Method C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484d5ce-c10f-4b76-a803-90de670da538",
   "metadata": {},
   "source": [
    "If folder names were saved previously, import them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a9094-7aea-466b-a689-f5c1ae6e6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the metadata directory.\n",
    "meta_dir = filedialog.askdirectory()\n",
    "project_filename = os.path.join(meta_dir, \"project_data.txt\")\n",
    "with open(project_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                var_name, var_value = line.split('=')\n",
    "                if var_name in globals():\n",
    "                    print(f\"{var_name} is {var_value}\")\n",
    "            except (ValueError):\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986ebe1-7f2e-4591-b8df-a6dbd6a21eeb",
   "metadata": {},
   "source": [
    "### 3. Stitching and Illumination Correction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713805",
   "metadata": {},
   "source": [
    "### 3.1 Stitching Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d7e45",
   "metadata": {},
   "source": [
    "The following cell defines the function that is called from the apply_basic function to stitch the corrected tiles.  It creates the model from the middle z-plane images of the first channel, and then applies the model to the rest of the images for all channels in the cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8598a778-b89c-4872-a1c6-a03819c37d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(images_transformed, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage):\n",
    "    \n",
    "    z = str(zplanes)\n",
    "    ch = str(channels)\n",
    "    pkl_dest = os.path.join(dest, \"result_df.pkl\")\n",
    "    \n",
    "    if zplanes == zplanes_n//2 and channels == 1:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(pkl_dest):\n",
    "            result_df = pd.read_pickle(pkl_dest)\n",
    "        else:\n",
    "            result_df, _ = stitch_images(images_transformed, rows, cols, initial_ncc_threshold=0.0, overlap_percentage=overlap_percentage, pou=pou, max_cores=20)\n",
    "            result_df.to_pickle(pkl_dest)\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(os.path.join(dest_1, \"result_df.pkl\")):\n",
    "            result_df = pd.read_pickle(os.path.join(dest_1, \"result_df.pkl\"))\n",
    "\n",
    "        else:\n",
    "            print(\"Run registration channel to produce a stitching model.\")\n",
    "\n",
    "    result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "    result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "    \n",
    "    size_y = images_transformed.shape[1]\n",
    "    size_x = images_transformed.shape[2]\n",
    "    \n",
    "    stitched_image_size = (\n",
    "        result_df[\"y_pos2\"].max() + size_y,\n",
    "        result_df[\"x_pos2\"].max() + size_x,\n",
    "    )\n",
    "    stitched_image = np.zeros_like(images_transformed, shape=stitched_image_size)\n",
    "    \n",
    "    for i, row in result_df.iterrows():\n",
    "        stitched_image[\n",
    "            row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "            row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "        ] = images_transformed[i]\n",
    "\n",
    "    result_image_file_path = os.path.join(dest,f\"{z.zfill(2)}.tif\") \n",
    "    imsave(result_image_file_path, stitched_image, check_contrast=False)\n",
    "    \n",
    "    print(f\"Saved to {result_image_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ff441",
   "metadata": {},
   "source": [
    "### 3.2 Illumination Correction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4328b6a-0eb6-4499-9e7e-27f040a60a14",
   "metadata": {},
   "source": [
    "The following cell contains the function that will apply the BaSiC correction to your data.  Make sure the number of leading zero digits in your cycle folder names is correct for 'zeros' and the filename pattern is correct for 'im_raw'.  This function runs BaSiC for the middle z-plane images and then reuses the correction model for the rest of the channel's images.  It then calls the stitching function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725a6802-1694-4881-85cf-21821ba0439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage):\n",
    "\n",
    "    zeros = 3\n",
    "    filename_pattern = f'1_000??_Z0{str(zplanes).zfill(2)}_CH{str(channels)}.tif'\n",
    "    \n",
    "    dest = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", f\"CH{str(channels)}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    dest_1 = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", \"CH1\")\n",
    "    \n",
    "    im_raw = sorted(glob(os.path.join(image_dir, f'cyc{str(cycles).zfill(zeros)}', filename_pattern)), key=alphanumeric_key)\n",
    "    im = io.imread_collection(im_raw)\n",
    "    im_array_init = np.asarray(im)\n",
    "    dtype_max = np.iinfo(im_array_init.dtype).max\n",
    "    im_array = im_array_init.astype(np.float64) / dtype_max\n",
    "\n",
    "    if not np.all(np.isfinite(im_array)):\n",
    "        raise ValueError(\"Input array contains inf or nan values\")\n",
    "    if np.any(im_array < 0):\n",
    "        raise ValueError(\"Input array contains negative values\")\n",
    "\n",
    "    print(f\"Start Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "    flatfield, darkfield = KCorrect.KCorrect(im_array, if_darkfield = True, max_iterations = 500, optimization_tolerance = 1e-6,  max_reweight_iterations=25, reweight_tolerance = 1.0e-3)\n",
    "    \n",
    "    if np.any(np.isnan(flatfield)) or np.any(np.isnan(darkfield)):\n",
    "        raise ValueError(\"Invalid flatfield or darkfield correction\")\n",
    "    if np.any(flatfield == 0):\n",
    "        warnings.warn(\"Flatfield contains zero values which may cause division issues\")\n",
    "    \n",
    "    corrected = np.zeros_like(im_array, dtype=np.float64)\n",
    "    for i in range(len(im_array)):\n",
    "        corrected[i] = ((im_array[i] - darkfield) / flatfield)\n",
    "        corrected[i] = np.clip(corrected[i], 0, 1)\n",
    "        \n",
    "    KCorrect.validate_correction(im_array_init, corrected)\n",
    "    corrected = (corrected * dtype_max).astype(np.uint16)                                       \n",
    "    stitch(corrected, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627091e-c1aa-4a7e-b6ef-a570bf28932d",
   "metadata": {},
   "source": [
    "### 3.3 Running multiple cycle/channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18604-75ad-4533-a9f9-b5dbe9785475",
   "metadata": {},
   "source": [
    "This cell runs the above two functions for all the images you define with start_cycle, end_cycle, start_channel, and end_channel.  You must enter these values as well as n, m, pou (determined from the first notebook), zplanes_n (number of zplanes), and overlap_percentage.  You must also enter the number of workers for the multithreading (usually determined by dataset size, available memory, and number of cores).  See https://docs.python.org/3/library/concurrent.futures.html\n",
    "\n",
    "To run just one cycle or channel, simply enter the same number for both start and end.\n",
    "\n",
    "If problems with the jupyter kernel restarting becomes an issue, decrease the number of workers, or close other programs to conserve resources.  You can also try reducing the histogram bins, number of iterations, and/or early_stop_n_iter_no_change values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3cbcadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Illumination Correction cyc01 Z008_CH2\n",
      "Start Stitching Z008_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\08.tif\n",
      "Start Illumination Correction cyc01 Z003_CH2Start Illumination Correction cyc01 Z005_CH2\n",
      "Start Illumination Correction cyc01 Z009_CH2\n",
      "Start Illumination Correction cyc01 Z015_CH2\n",
      "\n",
      "Start Illumination Correction cyc01 Z014_CH2\n",
      "Start Illumination Correction cyc01 Z007_CH2\n",
      "Start Illumination Correction cyc01 Z016_CH2\n",
      "Start Illumination Correction cyc01 Z001_CH2\n",
      "Start Illumination Correction cyc01 Z011_CH2\n",
      "Start Illumination Correction cyc01 Z017_CH2Start Illumination Correction cyc01 Z013_CH2\n",
      "\n",
      "Start Illumination Correction cyc01 Z012_CH2\n",
      "Start Illumination Correction cyc01 Z010_CH2\n",
      "Start Illumination Correction cyc01 Z002_CH2\n",
      "Start Illumination Correction cyc01 Z004_CH2Start Illumination Correction cyc01 Z006_CH2\n",
      "\n",
      "Start Stitching Z001_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\01.tif\n",
      "Significant change in relative intensities detected\n",
      "Significant change in relative intensities detected\n",
      "Significant change in relative intensities detected\n",
      "Start Stitching Z015_CH2\n",
      "Start Stitching Z003_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\15.tif\n",
      "Start Stitching Z016_CH2\n",
      "Start Stitching Z014_CH2Start Stitching Z017_CH2\n",
      "\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\16.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\14.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\17.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\03.tif\n",
      "Start Stitching Z004_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\04.tif\n",
      "Start Stitching Z013_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\13.tif\n",
      "Start Stitching Z012_CH2\n",
      "Start Stitching Z006_CH2\n",
      "Start Stitching Z005_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\12.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\06.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\05.tif\n",
      "Significant change in relative intensities detected\n",
      "Start Stitching Z002_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\02.tif\n",
      "Start Stitching Z007_CH2Start Stitching Z009_CH2\n",
      "\n",
      "Start Stitching Z010_CH2\n",
      "Start Stitching Z011_CH2\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\09.tifSaved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\07.tif\n",
      "\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\11.tif\n",
      "Saved to C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_BaSiC_Stitched\\cyc01\\CH2\\10.tif\n"
     ]
    }
   ],
   "source": [
    "n = 9  # Number of rows (height)\n",
    "m = 7  # Number of columns (width)\n",
    "\n",
    "# Row coordinates: each row index is repeated m times\n",
    "rows = list(chain.from_iterable(repeat(row, m) for row in range(n)))\n",
    "# Column coordinates: snake pattern for each row, going back and forth from top left going right\n",
    "cols = list(chain.from_iterable(range(m) if row % 2 == 0 else range(m - 1, -1, -1) for row in range(n)))\n",
    "\n",
    "start_cycle = 1\n",
    "end_cycle = 1\n",
    "start_channel = 2\n",
    "end_channel = 2\n",
    "pou = 13\n",
    "zplanes_n = 17\n",
    "overlap_percentage = 0.30\n",
    "workers = zplanes_n-1\n",
    "\n",
    "image_dir_list = [image_dir] * (zplanes_n-1)\n",
    "stitch_dir_list = [stitch_dir] * (zplanes_n-1)\n",
    "zplanes_list =[zplanes_n] * (zplanes_n-1)\n",
    "pou_list = [pou] * (zplanes_n-1)\n",
    "rows_list = [rows] * (zplanes_n-1)\n",
    "cols_list = [cols] * (zplanes_n-1)\n",
    "overlap_percentage_list = [overlap_percentage] * (zplanes_n-1)\n",
    "\n",
    "\n",
    "for j in range(start_cycle, end_cycle+1):\n",
    "    for i in range(start_channel, end_channel+1):\n",
    "\n",
    "        cycles = j\n",
    "        zplanes = zplanes_n//2 \n",
    "        channels = i\n",
    "        apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage)\n",
    "        \n",
    "        if __name__ ==  '__main__':\n",
    "            with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "                cycles = [j] * (zplanes_n-1) \n",
    "                zplanes =  list(range(1, zplanes_n//2))+list(range((zplanes_n//2)+1, zplanes_n+1)) \n",
    "                channels = [i] * (zplanes_n-1)\n",
    "                executor.map(apply_KCorrect, image_dir_list, stitch_dir_list, zplanes, cycles, channels, zplanes_list, pou_list, rows_list, cols_list, overlap_percentage_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3723d-e254-4bd1-bb5b-639f35e66dcc",
   "metadata": {},
   "source": [
    "### 4. Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fefaab-7c4a-4624-b85f-f26644b967f6",
   "metadata": {},
   "source": [
    "Before moving on to the deconvolution step, it is a good idea to review the results thus far.  If they are satisfactory, the parameters for deconvolution discovered in the first notebook can be entered below to define the decon function. Also, if more or all of the cycles have now been stitched, more deconvolution testing can be done on these stacks in the previous notebook before proceeding to a larger run. \n",
    "\n",
    "Be sure the MATLAB Runtime v9.5 (R2018, 64-bit) is installed.  Download for free here: http://www.mathworks.com/products/compiler/mcr/index.html. Reboot your computer after install.  \n",
    "\n",
    "There is no need to supply a point-spread function.\n",
    "\n",
    "The base_dir and stitch_dir definitions used previously will be again used here, and a new folder will be created to save the deconvolved images.  \n",
    "\n",
    "The original deconvolution program was written specifically for lightsheet images. Here the estimation of the point-spread function was modified for use with widefield fluorescence images.  See https://www.nature.com/articles/s41598-019-53875-y for the original publication which includes links to the original code.\n",
    "\n",
    "Output will be written to the terminal.  Check that the first image stack is processed without error.  If there is an \"Maximum variable size allowed on the device is exceeded.\" error, then restart the kernel, decrease the max_GPU or max_CPU parameter, rerun the decon function cell, and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00378f08",
   "metadata": {},
   "source": [
    "### 4.1 Deconvolution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a9e249-9b51-4bde-b711-0a40ddcd8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decon(cycles, channels):\n",
    "    \n",
    "    c = str(cycles)\n",
    "    ch = str(channels)\n",
    "\n",
    "    # pixel size in xy dimension (nanometers)\n",
    "    xy_vox = 377\n",
    "    # pixel size in z dimension (nanometers)\n",
    "    z_vox = 1500\n",
    "    # Number of iterations of Lucy-Richardson algo before stopping unless stop_crit is met first\n",
    "    iterations = 100\n",
    "    # Microscope objective numerical aperture\n",
    "    mic_NA = 0.75\n",
    "    # Refractive index of tissue being imaged\n",
    "    tissue_RI = 1.3\n",
    "    # Opening size in millimeters of objective aperture\n",
    "    slit_aper = 6.5\n",
    "    # Focal length in millimeters of objective\n",
    "    f_cyl = 1\n",
    "    # Used to reduce noise.  Increase value for noisy images. (0-10)\n",
    "    damping = 0\n",
    "    # If set, the deconvolved images will be clipped by this percent for max and min values, and then scaled to full range of bit depth. (0-5)\n",
    "    hist_clip = 0.01\n",
    "    # Percent change between iterations to use as criteria to stop deconvolution.\n",
    "    stop_crit = 5.00\n",
    "    # Enter 1 to perform on GPU, 0 to use CPU\n",
    "    GPU = 1\n",
    "    # Percent maximum GPU memory to use if GPU = 1\n",
    "    max_GPU = 20\n",
    "    # Percent maximum RAM to use if GPU = 0\n",
    "    max_CPU = 40\n",
    "    if GPU == 1:\n",
    "        max_block=max_GPU\n",
    "    elif GPU == 0:\n",
    "        max_block=max_CPU\n",
    "\n",
    "    # The respective excitation and emission wavelength in nanometers for each channel\n",
    "    C1ex = 358\n",
    "    C1em = 461\n",
    "    C2ex = 753\n",
    "    C2em = 775\n",
    "    C3ex = 560\n",
    "    C3em = 575\n",
    "    C4ex = 648\n",
    "    C4em = 668\n",
    "    \n",
    "    # The path to the deconvolution executable file.\n",
    "    decon_exe = \"C:/Users/smith6jt/KINTSUGI/LsDeconv.exe\"\n",
    "    stitch_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_BaSiC_Stitched\"\n",
    "    decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "    source = os.path.join(stitch_dir, f\"cyc{c.zfill(2)}\", f\"CH{ch}\")\n",
    "    dest = os.path.join(decon_dir, f\"cyc{c.zfill(2)}\", f\"CH{ch}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting Deconvolution of cyc{c.zfill(2)} CH{ch}\")\n",
    "   \n",
    "    if channels==1:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C1ex), str(C1em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "        # print(result_1.stdout)\n",
    "    if channels==2:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C2ex), str(C2em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    if channels==3:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C3ex), str(C3em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    if channels==4:\n",
    "        subprocess.run([decon_exe, source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(C4ex), str(C4em), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_crit), str(max_block), str(GPU)])\n",
    "    # gc.collect()\n",
    "    \n",
    "    try:\n",
    "        os.rename(os.path.join(source, 'deconvolved'), os.path.join(dest, 'deconvolved'))\n",
    "    except (FileNotFoundError):\n",
    "        print(\"Reduce max memory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6e5d-b464-4f7d-bf8f-d3c542249366",
   "metadata": {},
   "source": [
    "To apply the above decon function to multiple cycles/channels, enter the start and end numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd44c0-b01d-473e-ade7-da609559d9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decon_start_cycle = 1\n",
    "decon_end_cycle = 1\n",
    "decon_start_channel = 2\n",
    "decon_end_channel = 4\n",
    "\n",
    "\n",
    "for j in range(decon_start_cycle, decon_end_cycle+1):\n",
    "    \n",
    "    for i in range(decon_start_channel, decon_end_channel+1):\n",
    "        \n",
    "        \n",
    "        decon( j, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948e5f2",
   "metadata": {},
   "source": [
    "### 5. Extended Depth of Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ceac06-e6aa-41d0-bbbf-263d7e6d0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0f525",
   "metadata": {},
   "source": [
    "### 5.1 ImageJ FIJI macro running Clij2 plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej, scyjava\n",
    "vipshome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\vips-dev-8.16\\\\bin'\n",
    "javahome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\jdk-21_windows-x64_bin\\\\jdk-21.0.5\\\\bin'\n",
    "mavenhome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\apache-maven-3.9.9-bin\\\\apache-maven-3.9.9\\\\bin'\n",
    "os.environ['PATH'] = vipshome + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "ij_mem = 40\n",
    "GPU_name = \"NVIDIA RTX A4500\"\n",
    "radius_x = 5.0\n",
    "radius_y = 5.0\n",
    "sigma = 20.0\n",
    "edf_start_cycle = 1\n",
    "edf_end_cycle = 1\n",
    "edf_start_channel = 1\n",
    "edf_end_channel = 4\n",
    "scyjava.config.add_option(f'-Xmx{str(ij_mem)}g')\n",
    "ij = imagej.init('C:/Users/smith6jt/Fiji.app', add_legacy=False)\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "edf_dir = decon_dir.replace('_Decon', '_EDF')\n",
    "\n",
    "macro = \"\"\"\n",
    "#@ File in_folder\n",
    "#@ String device\n",
    "#@ File out_folder\n",
    "#@ String file_name\n",
    "#@ Integer radius_x\n",
    "#@ Integer radius_y\n",
    "#@ Integer sigma\n",
    "\n",
    "File.openSequence(in_folder);\n",
    "run(\"CLIJ2 Macro Extensions\", \"cl_device=[\" + device + \"]\");\n",
    "Ext.CLIJ_clear();\n",
    "image1 = \"deconvolved\";\n",
    "Ext.CLIJ2_push(image1);\n",
    "image2 = \"extended_depth_of_focus_variance_projection\";\n",
    "radius_x = 5.0;\n",
    "radius_y = 5.0;\n",
    "sigma = 20.0;\n",
    "Ext.CLIJ2_extendedDepthOfFocusVarianceProjection(image1, image2, radius_x, radius_y, sigma);\n",
    "Ext.CLIJ2_pull(image2);\n",
    "selectImage(image1);\n",
    "close();\n",
    "selectImage(image2);\n",
    "saveAs(\"Tiff\", out_folder + File.separator + file_name);\n",
    "\"\"\"\n",
    "\n",
    "for j in range(edf_start_cycle, edf_end_cycle+1):\n",
    "    \n",
    "    for i in range(edf_start_channel, edf_end_channel+1):\n",
    "\n",
    "        edf_source = os.path.join(decon_dir, f\"cyc{str(j).zfill(2)}\", f\"CH{str(i)}\", \"deconvolved\")\n",
    "        edf_dest = os.path.join(edf_dir, f\"cyc{str(j).zfill(2)}\")\n",
    "        file_name = channel_name_dict.get(f\"cyc{str(j).zfill(2)}.tif\")[i-1]\n",
    "        os.makedirs(edf_dest, exist_ok=True)\n",
    "\n",
    "        args ={'in_folder': edf_source, \"cl_device\" : GPU_name, \"out_folder\" : edf_dest, \"file_name\" : file_name, \"radius_x\" : 5.0, \"radius_y\" : 5.0, \"sigma\" : 20.0}\n",
    "        ij.py.run_macro(macro, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c5fe8",
   "metadata": {},
   "source": [
    "### 6. Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c6a31",
   "metadata": {},
   "source": [
    "### 6.1 Combine channels for each cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed7315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823171b5d2174d61acb2ed4f374a841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_start_cycle = 5\n",
    "reg_end_cycle = 13\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.WARN) #change to INFO for more details\n",
    "vipshome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\vips-dev-8.16\\\\bin'\n",
    "os.environ['PATH'] = vipshome + ';' + os.environ['PATH']\n",
    "import sys\n",
    "import pyvips \n",
    "import uuid\n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "os.makedirs(reg_dir, exist_ok=True)\n",
    "\n",
    "pbar_filesave = tqdm(total=100, unit=\"Percent\",\n",
    "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True)\n",
    "\n",
    "for j in range(reg_start_cycle, reg_end_cycle + 1):\n",
    "\n",
    "    cycle= f\"cyc{str(j).zfill(2)}\" \n",
    "     \n",
    "    reg_source = os.path.join(edf_dir, f\"cyc{str(j).zfill(2)}\") \n",
    "    image_set = glob(os.path.join(reg_source, '*.tif'))\n",
    "    channel_name_order = channel_name_dict.get(f\"cyc{str(j).zfill(2)}.tif\")\n",
    "    image_set.sort(key=lambda x: channel_name_order.index(os.path.basename(x).split('.')[0]))\n",
    "  \n",
    "    channel_names = []\n",
    "    for i in range(len(image_set)):\n",
    "        split_name = os.path.basename(image_set[i].split(\".\")[0])\n",
    "        channel_names.append(split_name)\n",
    " \n",
    "    pyvips_image_set = [pyvips.Image.new_from_file(os.path.join(reg_source, filename), access=\"sequential\") for filename in image_set]\n",
    "\n",
    "    out_init = pyvips.Image.arrayjoin(pyvips_image_set, across=1)\n",
    "    out = out_init.copy()\n",
    "    out.set_type(pyvips.GValue.gint_type, \"page-height\", pyvips_image_set[0].height)\n",
    "\n",
    "    x_dim = pyvips_image_set[0].width\n",
    "    y_dim = pyvips_image_set[0].height\n",
    "    data_type = \"uint16\"  \n",
    "    pixel_size = float(0.377)\n",
    "    bands = len(pyvips_image_set)\n",
    "    outfile = os.path.join(reg_dir, f'cyc{str(j).zfill(2)}.ome.tif')\n",
    "    out.set_type(pyvips.GValue.gstr_type, \"image-description\",\n",
    "    f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "        <OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "            xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "            xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\">\n",
    "            <Image ID=\"Image:0\" Name=\"{cycle}\" >\n",
    "                <!-- Minimum required fields about image dimensions -->\n",
    "                <Pixels BigEndian=\"false\"\n",
    "                        DimensionOrder=\"XYCZT\" \n",
    "                        ID=\"Pixels:0\"\n",
    "                        Interleaved=\"false\"\n",
    "                        SignificantBits=\"16\"                                              \n",
    "                        SizeC=\"{bands}\" \n",
    "                        SizeT=\"1\" \n",
    "                        SizeX=\"{x_dim}\" \n",
    "                        SizeY=\"{y_dim}\" \n",
    "                        SizeZ=\"1\" \n",
    "                        Type=\"{data_type}\" \n",
    "                        PhysicalSizeX=\"{pixel_size}\" \n",
    "                        PhysicalSizeY=\"{pixel_size}\">\n",
    "                    <TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"16751615\" ID=\"Channel:0:0\" Name=\"{channel_names[0]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"1\" FirstT=\"0\" FirstZ=\"0\" IFD=\"1\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"7995391\" ID=\"Channel:0:1\" Name=\"{channel_names[1]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"2\" FirstT=\"0\" FirstZ=\"0\" IFD=\"2\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"9043967\" ID=\"Channel:0:2\" Name=\"{channel_names[2]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"3\" FirstT=\"0\" FirstZ=\"0\" IFD=\"3\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"1828651263\" ID=\"Channel:0:3\" Name=\"{channel_names[3]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                </Pixels>\n",
    "            </Image>\n",
    "        </OME>\"\"\")\n",
    "\n",
    "    out.tiffsave(outfile, subifd=True, page_height=y_dim, compression='lzw', tile=True,\n",
    "                  tile_width=512, tile_height=512, pyramid=True, bigtiff=True)\n",
    "    out_init = None\n",
    "    out = None\n",
    "    pyvips_image_set = None\n",
    "    gc.collect() \n",
    "    pbar_filesave.update(100 / (reg_end_cycle - reg_start_cycle + 1))\n",
    "\n",
    "pbar_filesave.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca3579",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b3abfed",
   "metadata": {},
   "source": [
    "### 6.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d56ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smith6jt\\AppData\\Local\\miniforge3\\envs\\KINTSUGI\\lib\\site-packages\\valis\\valtils.py:25: UserWarning: Can't find slide file associated with valis_out\n",
      "  warnings.warn(warning_msg, warning_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Converting images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:   0%|          | 0/13 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc01>, width=9963, height=9484, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C70C93D7C0> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:   8%|▊         | 1/13 [00:00<00:04,  2.55image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc02>, width=9964, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA6D00> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  15%|█▌        | 2/13 [00:00<00:04,  2.60image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc03>, width=9960, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CC8FD0> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  23%|██▎       | 3/13 [00:01<00:03,  2.55image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc04>, width=9960, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA69A0> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  31%|███       | 4/13 [00:01<00:03,  2.67image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc05>, width=9961, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA6FD0> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  38%|███▊      | 5/13 [00:01<00:02,  2.78image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc06>, width=9963, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C70EC94BB0> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  46%|████▌     | 6/13 [00:02<00:02,  2.68image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc07>, width=9962, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA6E50> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  54%|█████▍    | 7/13 [00:02<00:02,  2.58image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc08>, width=9961, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C70C966D90> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  62%|██████▏   | 8/13 [00:03<00:01,  2.54image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc09>, width=9963, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C70DB47F10> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  69%|██████▉   | 9/13 [00:03<00:01,  2.54image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc10>, width=9963, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA6130> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  77%|███████▋  | 10/13 [00:03<00:01,  2.55image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc11>, width=9961, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CC8850> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  85%|████████▍ | 11/13 [00:04<00:00,  2.64image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc12>, width=9961, height=9485, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CA6970> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  92%|█████████▏| 12/13 [00:04<00:00,  2.58image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc13>, width=9963, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <valis.slide_io.VipsSlideReader object at 0x000001C754CC8D30> False (975, 1024, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images: 100%|██████████| 13/13 [00:05<00:00,  2.57image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processing images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images : 100%|██████████| 13/13 [00:07<00:00,  1.79image/s]\n",
      "Normalizing images: 100%|██████████| 13/13 [00:00<00:00, 21.46image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Rigid registration\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting features   : 100%|██████████| 13/13 [02:05<00:00,  9.68s/image]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb8c2e1a66143a6b9e3516d0600c141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2823bfacd54e06ab4743a3ebeef25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3522b1574afb4ef29f8822af9f4e0243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding transforms   : 100%|██████████| 12/12 [00:00<00:00, 2995.04image/s]\n",
      "Finalizing           : 100%|██████████| 13/13 [00:00<00:00, 13902.59image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Rigid registration complete in 2.272 minutes\n",
      "\n",
      "\n",
      "==== Non-rigid registration\n",
      "\n",
      "Creating non-rigid mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing images for non-rigid registration: 100%|██████████| 13/13 [00:06<00:00,  1.94image/s]\n",
      "Finding non-rigid transforms: 100%|██████████| 12/12 [00:48<00:00,  4.04s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Non-rigid registration complete in 48.686 seconds\n",
      "\n",
      "\n",
      "==== Measuring error\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring error: 100%|██████████| 13/13 [00:01<00:00,  6.76image/s]\n",
      "Preparing images for non-rigid registration: 100%|██████████| 13/13 [04:02<00:00, 18.62s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Performing microregistration\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding non-rigid transforms: 100%|██████████| 12/12 [28:21<00:00, 141.76s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Non-rigid registration complete in 28.444 minutes\n",
      "\n",
      "\n",
      "==== Measuring error\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring error: 100%|██████████| 13/13 [01:12<00:00,  5.56s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging DAPI (cyc08), CD34 (cyc08), CD44 (cyc08), HLADR (cyc08) from cyc08\n",
      "merging DAPI (cyc12), Empty12a (cyc12), CD5 (cyc12), CD1c (cyc12) from cyc12\n",
      "merging DAPI (cyc13), Blank13a (cyc13), Blank13b (cyc13), Blank13c (cyc13) from cyc13\n",
      "merging DAPI (cyc10), Empty10a (cyc10), CollagenIV (cyc10), Vimentin (cyc10) from cyc10\n",
      "merging DAPI (cyc09), Empty9a (cyc09), FoxP3 (cyc09), CD163 (cyc09) from cyc09\n",
      "merging DAPI (cyc02), CD31 (cyc02), CD8 (cyc02), Empty2c (cyc02) from cyc02\n",
      "merging DAPI (cyc11), Empty11a (cyc11), CD15 (cyc11), CD45 (cyc11) from cyc11\n",
      "merging DAPI (cyc07), CD35 (cyc07), ECAD (cyc07), CD107a (cyc07) from cyc07\n",
      "merging DAPI (cyc01), Blank1a (cyc01), Blank1b (cyc01), Blank1c (cyc01) from cyc01\n",
      "merging DAPI (cyc03), CD20 (cyc03), Ki67 (cyc03), CD3e (cyc03) from cyc03\n",
      "merging DAPI (cyc04), SMActin (cyc04), Podoplanin (cyc04), CD68 (cyc04) from cyc04\n",
      "merging DAPI (cyc05), PanCK (cyc05), CD21 (cyc05), CD4 (cyc05) from cyc05\n",
      "merging DAPI (cyc06), Lyve1 (cyc06), CD45RO (cyc06), CD11c (cyc06) from cyc06\n",
      "saving C:/Users/smith6jt/KINTSUGI/data/1904_CC2B28_Registration\\merged_1904_CC2B28.ome.tif (9952 x 9496 and 52 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 14.026 hourss\n",
      "Complete\n",
      "\n",
      "JVM has been killed. If this was due to an error, then a new Python session will need to be started\n"
     ]
    }
   ],
   "source": [
    "vipshome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\vips-dev-8.16\\\\bin'\n",
    "javahome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\jdk-21_windows-x64_bin\\\\jdk-21.0.5\\\\bin'\n",
    "mavenhome = 'C:\\\\Users\\\\smith6jt\\\\KINTSUGI\\\\apache-maven-3.9.9-bin\\\\apache-maven-3.9.9\\\\bin'\n",
    "os.environ['PATH'] = vipshome + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "import sys\n",
    "import pyvips\n",
    "from valis import registration, slide_io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# registration.init_jvm()\n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "\n",
    "slide_src_dir = reg_dir\n",
    "results_dst_dir = os.path.join(reg_dir, \"valis_out\")\n",
    "merged_slide_dst_f = os.path.join(reg_dir, \"merged_1904_CC2B28.ome.tif\")\n",
    "\n",
    "max_processed_image_dim_px = 300\n",
    "max_non_rigid_registration_dim_px = 5500\n",
    "registrar = registration.Valis(slide_src_dir, results_dst_dir, crop=\"overlap\")\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "registrar.register_micro(max_non_rigid_registration_dim_px=max_non_rigid_registration_dim_px, align_to_reference=False)\n",
    "merged_img, channel_names, ome_xml = registrar.warp_and_merge_slides(merged_slide_dst_f,\n",
    "                                    crop=\"overlap\",\n",
    "                                    drop_duplicates=True)\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52935c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KINTSUGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
